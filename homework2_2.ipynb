{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6lN7Uzc4cN-",
    "outputId": "58889129-ed33-4f89-f81a-b938f96fb7bf"
   },
   "outputs": [],
   "source": [
    "from importnb import Notebook \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9eOMFP8509Na"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class layer:\n",
    "    def __init__(self,Input_len,nodenum,acti_name):\n",
    "        self.nodenum = nodenum\n",
    "        # temp =  np.full((Input_len+1,nodenum),1)\n",
    "        # self.Input_w = np.random.random( (Input_len+1,nodenum) )*2-temp\n",
    "        # self.Input_w = np.random.random(Input_len+1,nodenum)\n",
    "#         self.Input_w = np.full((Input_len+1,nodenum),0.5)\n",
    "        self.Input_w = np.random.randn(Input_len+1,nodenum)/np.sqrt(Input_len+1)\n",
    "        if acti_name == 'relu':\n",
    "            self.actiFunc = self.relu\n",
    "            self.actiFunc_diff = self.drelu\n",
    "        elif acti_name == 'softmax':\n",
    "            self.actiFunc = self.softmax\n",
    "            self.actiFunc_diff = self.dsoftmax   # 隨便給\n",
    "        elif acti_name == 'sigmoid':\n",
    "            self.actiFunc = self.sigmoid\n",
    "            self.actiFunc_diff = self.dsigmoid\n",
    "            \n",
    "    def give_input(self,Input):\n",
    "        self.Input = Input.copy()\n",
    "        \n",
    "    def cal_output(self):\n",
    "        # 算出系統output\n",
    "        self.weighted_Input = np.dot(self.Input, self.Input_w)\n",
    "        self.Output = self.actiFunc(self.weighted_Input)\n",
    "#         print(\"in: \", self.Input, \"w: \", self.Input_w, \"out: \", self.Output)\n",
    "        return self.Output\n",
    "    \n",
    "    \"\"\" Activation function & Differential function \"\"\"  \n",
    "    def relu(self,x_value):\n",
    "        x_value[x_value<=0] = 0\n",
    "        return x_value.copy()\n",
    "    \n",
    "    def drelu(self,x_value):\n",
    "        x_value[x_value > 0] = 1\n",
    "        x_value[x_value < 0] = 0\n",
    "        return x_value.copy()\n",
    "            \n",
    "    def softmax(self,x_value):\n",
    "        x_value = x_value-np.max(x_value)\n",
    "        return np.exp(x_value)/ np.sum(np.exp(x_value))\n",
    "    \n",
    "    def dsoftmax(self,x_value):\n",
    "        return 1\n",
    "\n",
    "    def sigmoid(self,x_value):\n",
    "        output = 1/(1+np.exp(-x_value))\n",
    "        return output\n",
    "        \n",
    "    def dsigmoid(self,x_value):    \n",
    "        return np.exp(-x_value)/np.square( (1+np.exp(-x_value)) )\n",
    "        \n",
    "#         self.Input_w = np.full((Input_len+1,nodenum),0.5)\n",
    "#         self.Input_w =  np.random.random( (Input_len+1,nodenum) ) # 加一是因為把bias含進去weight裡面\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Rxm_oNpx1FEQ"
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self,loss_name,learn_rate,data_list,input_len):\n",
    "        self.Layer_list = list() # 把 layer 按照先後順序放入\n",
    "        self.input_len = input_len   # 要給輸入長度才有辦法使用 model_input\n",
    "        self.learn_rate = learn_rate\n",
    "        self.model_input = data_list  # 輸入加答案(方便洗牌)\n",
    "        self.standard = list()\n",
    "        \n",
    "        if loss_name == 'MSE':\n",
    "            self.loss_diff = self.mse_diff\n",
    "        elif loss_name == 'cross_entropy':\n",
    "            self.loss_diff = self.dsoftmax_entropy\n",
    "    \n",
    "    # train model        \n",
    "    def model_train(self,Iter,epoch):\n",
    "        for i in range(Iter):\n",
    "            # np.random.shuffle(self.model_input)\n",
    "            correct=list()\n",
    "            loss = list()\n",
    "            for j in range(int(len(self.model_input)/epoch)):\n",
    "                \n",
    "                \n",
    "                temp_input = self.model_input[j*epoch:(j+1)*epoch]\n",
    "                bp_input = np.zeros(self.Layer_list[len(self.Layer_list)-1].nodenum)\n",
    "                output = list()\n",
    "                ans = list()\n",
    "                for item in temp_input:\n",
    "#                     print(item, \"s, \", item[0:self.input_len],item[self.input_len:len(item)])\n",
    "                    temp_op,temp_bpip = self.forward_pass(item[0:self.input_len],item[self.input_len:len(item)])\n",
    "                    output.append(temp_op.copy())\n",
    "                    ans.append(item[self.input_len:len(item)])\n",
    "                    bp_input += temp_bpip.copy()\n",
    "#                     for k in range(len(temp_bpip)):\n",
    "#                         bp_input[k] += temp_bpip[k]\n",
    "                    loss.append( - np.sum(item[self.input_len:len(item)] * np.log(temp_op)))\n",
    "                    \n",
    "                    # print(\"output\",output)\n",
    "                self.backpropagation(bp_input/epoch)\n",
    "                correct.append(self.dealoutput(output,ans))\n",
    "            print(\"第\",i,np.average(correct), \"loss: \", np.average(loss))\n",
    "    \n",
    "    def model_test(self,testdata_list):\n",
    "        for item in testdata_list:\n",
    "            temp_op,temp_bpip = self.forward_pass(item[0:self.input_len],item[self.input_len:len(item)])  \n",
    "            output.append(temp_op)\n",
    "            ans.append(item[len(item)-1])\n",
    "        correct = self.dealoutput(output,ans)\n",
    "        print(\"正確率\",correct)\n",
    "        \n",
    "    # 加入 layer \n",
    "    def setlayer(self,List):  \n",
    "        self.Layer_list = List.copy()\n",
    "        \n",
    "    \"\"\" loss function \"\"\" \n",
    "    def mse_diff(self,output,standard):\n",
    "#         print(output-standard)\n",
    "        return output-standard\n",
    "    \n",
    "    def dsoftmax_entropy(self,output,standard):\n",
    "#         print(\"output: \",output, \"std: \", standard, \"diff: \", output-standard)\n",
    "        return output-standard\n",
    "    \n",
    "    def forward_pass(self,Input,standard):\n",
    "        # 進行一次 input forward pass運算\n",
    "        Input = np.append(Input.copy(),1)\n",
    "        self.Layer_list[0].give_input(Input) \n",
    "#         print(self.Layer_list)\n",
    "        for i in range(len(self.Layer_list)):\n",
    "            # 前一層output當做下一層的輸入 \n",
    "            output = self.Layer_list[i].cal_output()\n",
    "            if i+1< len(self.Layer_list):\n",
    "                output = np.append(output,1)\n",
    "                self.Layer_list[i+1].give_input(output)\n",
    "        bp_input = self.loss_diff(output,standard)\n",
    "        return output,bp_input  # 最終output\n",
    "\n",
    "#     def backpropagation(self,bp_input):\n",
    "#         layer_reverse = self.Layer_list.copy()\n",
    "#         layer_reverse.reverse()\n",
    "#         for layer in layer_reverse:\n",
    "#             # print('before in: ',bp_input,\"df: \", layer.actiFunc_diff(layer.weighted_Input))\n",
    "#             bp_error = bp_input*layer.actiFunc_diff(layer.weighted_Input)\n",
    "#             # print(self.learn_rate,bp_error,layer)\n",
    "#             Input_w = layer.Input_w.transpose()\n",
    "#             bp_input = bp_error.dot(Input_w[:,0:len(Input_w[0])-1])\n",
    "# #             print('before',layer.Input_w)\n",
    "#             for i in range(len(layer.Input)):\n",
    "#                 # print(\"in \", i, self.learn_rate,bp_error,layer.Input[i])\n",
    "#                 layer.Input_w[i] = layer.Input_w[i] - self.learn_rate*bp_error*layer.Input[i]\n",
    "#                 # print(\"第\",i,layer.Input_w[i])\n",
    "# #             print('after',layer.Input_w)\n",
    "#         # self.Layer_list = layer_reverse.reverse()\n",
    "    \n",
    "    def backpropagation(self,bp_input):\n",
    "        for j in range(len(self.Layer_list)-1, -1, -1):\n",
    "            layer = self.Layer_list[j]\n",
    "            delta = bp_input * layer.actiFunc_diff(layer.weighted_Input)    # Dimation of layer node\n",
    "            delta_w = np.outer(layer.Input, delta)\n",
    "            bp_input = np.dot(delta, layer.Input_w[0:len(layer.Input_w)-1, :].transpose())\n",
    "            layer.Input_w -= self.learn_rate*delta_w\n",
    "    \n",
    "    def dealoutput(self,output,standard):\n",
    "        result = list()\n",
    "        for i in range(len(output)):\n",
    "            ans = 1 if np.argmax(output[i]) == np.argmax(standard[i]) else 0 \n",
    "            result.append(ans)\n",
    "#         print(\"print\",result.count(1),len(result))\n",
    "        \n",
    "        correct = np.average(result)\n",
    "#         for i in range(len(output)):\n",
    "#             print(\"output: \",output[i], \"std: \", standard[i], \"result: \", result[i], \"correct: \", correct)\n",
    "#         print(\"correct: \", correct)\n",
    "        \n",
    "#         while True:\n",
    "#             pass\n",
    "        return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(image_dir, label_dir):\n",
    "    with open(image_dir, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        \n",
    "        buf = file.read(size * rows * cols)\n",
    "        img_data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        img_data = img_data.reshape(size, rows*cols)\n",
    "        img_data = img_data / 255\n",
    "        \n",
    "    \n",
    "    with open(label_dir, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        \n",
    "        buf = file.read(size)\n",
    "        lab_data_tmp = np.frombuffer(buf, dtype=np.uint8).astype(np.uint16)\n",
    "        lab_data_tmp = lab_data_tmp.reshape(size)\n",
    "        \n",
    "#     print(lab_data[0:111])\n",
    "    lab_data = np.zeros((size, 10), dtype=np.uint16)\n",
    "    for i in range(size):\n",
    "        lab_data[i][ lab_data_tmp[i] ] = 1\n",
    "    \n",
    "#     print(lab_data[0:10])\n",
    "    \n",
    "    \n",
    "    return img_data.copy(), lab_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.frombuffer(b'\\x02\\x01\\x00\\x00', dtype=np.uint16))\n",
    "X_train, Y_train  = read_data('code/MNIST/train-images-idx3-ubyte', 'code/MNIST/train-labels-idx1-ubyte')\n",
    "X_test, Y_test  = read_data('code/MNIST/t10k-images-idx3-ubyte', 'code/MNIST/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ydrdbj-K3pJz"
   },
   "outputs": [],
   "source": [
    "\"\"\"處理輸入資料\"\"\"\n",
    "\n",
    "# Load MNIST data\n",
    "train_data = np.append(X_train,Y_train, axis=1)\n",
    "# 合併資料跟答案\n",
    "# for i in range(len(X_train)):\n",
    "#     train_data.append(X_train[i],Y_train[i])\n",
    "\n",
    "# print(train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "9GAqxUmc3pJ2",
    "outputId": "3283a4f0-4f3a-4c36-8949-8c87889fcc96",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 0.9042666666666667 loss:  0.316989316683963\n",
      "第 1 0.9572 loss:  0.1440500488037263\n",
      "第 2 0.9660833333333333 loss:  0.11306652652206726\n",
      "第 3 0.9725333333333334 loss:  0.09277404722163868\n",
      "第 4 0.97605 loss:  0.08064843650671025\n",
      "第 5 0.9781333333333333 loss:  0.07204221415269849\n",
      "第 6 0.9799833333333333 loss:  0.06582101031220143\n",
      "第 7 0.9816666666666667 loss:  0.05876553826248052\n",
      "第 8 0.9821 loss:  0.05665563586138602\n",
      "第 9 0.98375 loss:  0.05174067997683998\n",
      "第 10 0.9843333333333333 loss:  0.049121671489253775\n",
      "第 11 0.98545 loss:  0.04632806750421893\n",
      "第 12 0.9867 loss:  0.043570346663668644\n",
      "第 13 0.9874 loss:  0.04068261734073044\n",
      "第 14 0.9877166666666667 loss:  0.039416989683056666\n",
      "第 15 0.9876 loss:  0.03863257849991415\n",
      "第 16 0.9883333333333333 loss:  0.03652969450807379\n",
      "第 17 0.9890166666666667 loss:  0.03410382174364254\n",
      "第 18 0.9896166666666667 loss:  0.03182942072164167\n",
      "第 19 0.9888 loss:  0.03540446467399903\n",
      "第 20 0.9901 loss:  0.03138166758875857\n",
      "第 21 0.9896333333333334 loss:  0.03258999434660195\n",
      "第 22 0.9894166666666667 loss:  0.033708011241832335\n",
      "第 23 0.9912 loss:  0.0281101144117545\n",
      "第 24 0.9906166666666667 loss:  0.029704521355598208\n",
      "第 25 0.99075 loss:  0.029763489456441552\n",
      "第 26 0.9910833333333333 loss:  0.027555179555731543\n",
      "第 27 0.9917333333333334 loss:  0.026539861357643534\n",
      "第 28 0.9922666666666666 loss:  0.025354010728738635\n",
      "第 29 0.9929166666666667 loss:  0.022863571136530744\n",
      "第 30 0.9924166666666666 loss:  0.02410444636067298\n",
      "第 31 0.99235 loss:  0.024352959313434792\n",
      "第 32 0.9927833333333334 loss:  0.02341264155668942\n",
      "第 33 0.9925333333333334 loss:  0.02374679247695267\n",
      "第 34 0.9919333333333333 loss:  0.026511160933874456\n",
      "第 35 0.9922166666666666 loss:  0.026285111339869636\n",
      "第 36 0.9928333333333333 loss:  0.02253085382634357\n",
      "第 37 0.9932333333333333 loss:  0.022141876116509984\n",
      "第 38 0.9948833333333333 loss:  0.01576781938505685\n",
      "第 39 0.9941333333333333 loss:  0.01961553222920134\n",
      "第 40 0.9928833333333333 loss:  0.023219959463489787\n",
      "第 41 0.9939833333333333 loss:  0.01845990488707444\n",
      "第 42 0.99435 loss:  0.01875345331400526\n",
      "第 43 0.9951333333333333 loss:  0.016490125550648053\n",
      "第 44 0.9936333333333334 loss:  0.021634864448409234\n",
      "第 45 0.9932333333333333 loss:  0.02127355960011374\n",
      "第 46 0.99425 loss:  0.019378001954366147\n",
      "第 47 0.994 loss:  0.018033121491220414\n",
      "第 48 0.9943 loss:  0.01868997313580063\n",
      "第 49 0.9941833333333333 loss:  0.019443744481250098\n",
      "第 50 0.9942333333333333 loss:  0.019442784925156074\n",
      "第 51 0.9943833333333333 loss:  0.019166614005860547\n",
      "第 52 0.9961833333333333 loss:  0.013461052193736531\n",
      "第 53 0.9952666666666666 loss:  0.01627901362545178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-06f2e58aa453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlayer_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-24bb64cafcc5>\u001b[0m in \u001b[0;36mmodel_train\u001b[1;34m(self, Iter, epoch)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[1;31m# print(\"output\",output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbp_input\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                 \u001b[0mcorrect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdealoutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"第\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"loss: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-24bb64cafcc5>\u001b[0m in \u001b[0;36mbackpropagation\u001b[1;34m(self, bp_input)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayer_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbp_input\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactiFunc_diff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweighted_Input\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# Dimation of layer node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0mdelta_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m             \u001b[0mbp_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput_w\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mouter\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\nn_class\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mouter\u001b[1;34m(a, b, out)\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"進行訓練\"\"\"\n",
    "test_input = train_data\n",
    "test_model = model(\"cross_entropy\",0.0047,test_input,784) # loss_name,learn_rate,model_input,input_len\n",
    "\n",
    "# layer1 = layer(14,65,'sigmoid') #Input_len,nodenum,acti_name\n",
    "# layer2 = layer(65,32,'relu') #Input_len,nodenum,acti_name\n",
    "# layer3 = layer(32,1,'sigmoid') #Input_len,nodenum,acti_name\n",
    "\n",
    "layer1 = layer(784,50,'relu') #Input_len,nodenum,acti_name\n",
    "layer2 = layer(50,23,'relu') #Input_len,nodenum,acti_name\n",
    "layer3 = layer(23,17,'relu') #Input_len,nodenum,acti_name\n",
    "layer4 = layer(17,10,'softmax') #Input_len,nodenum,acti_name\n",
    "\n",
    "layer_list = [layer1,layer2,layer3,layer4]\n",
    "test_model.setlayer(layer_list)\n",
    "test_model.model_train(5000,1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework2_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
