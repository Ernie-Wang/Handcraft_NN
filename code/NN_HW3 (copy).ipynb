{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1604123731048,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "9ubVx3EUDU9W"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ97WqKes3b-"
   },
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1604123731341,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "fAr38nImf4XO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Model class for the network model\n",
    "Store the model, including layer(construct by node), activation function\n",
    "'''\n",
    "class Model():\n",
    "    def __init__(self, func, d_func, layer_nums, input_list, lr_rate):\n",
    "        self.act_func = func                    # Activation function\n",
    "        self.d_act_func = d_func                # Diviation of activate function\n",
    "\n",
    "        self.layer_nums = layer_nums.copy()     # List of the number of each layer\n",
    "                                                # 0 => input number\n",
    "                                                # middle => layer number\n",
    "                                                # last => output number\n",
    "\n",
    "        self.input_list = input_list.copy()     # Store the list for model input\n",
    "        self.result = 0                         # Initial network result\n",
    "        self.lr_rate = lr_rate                  # Learning rate\n",
    "        self.layer_list = np.full(len(self.layer_nums), None)\n",
    "        self.loss = 0\n",
    "\n",
    "        # Creating the network\n",
    "        # self.intput_nodes = np.full(self.layer_nums[0], 0.0)   # Initial input variable\n",
    "        # print( \"0-th layer\")\n",
    "        self.layer_list[0] = Layer(self.act_func, self.d_act_func, len(self.input_list), self.input_list, self.lr_rate, True)\n",
    "        for i in range(1, len(self.layer_nums)):\n",
    "    #       print(i, \"-th layer\")\n",
    "            self.layer_list[i] = Layer(self.act_func, self.d_act_func, self.layer_nums[i], self.layer_list[i-1].get_node_list().copy(), self.lr_rate, False)\n",
    "    \n",
    "\n",
    "\n",
    "    '''\n",
    "    Calculate the network by using input data\n",
    "    '''\n",
    "    def cal_network(self, input):\n",
    "        self.layer_list[0].set_input(input.copy())\n",
    "        for i, layer in enumerate(self.layer_list):\n",
    "            layer.cal_output()\n",
    "\n",
    "        return self.get_result()\n",
    "\n",
    "    '''\n",
    "    Set output errors, for the last layer only\n",
    "    '''\n",
    "    def set_output_error(self, error):\n",
    "        self.layer_list[len(self.layer_nums)-1].set_output_error(error)\n",
    "  \n",
    "    '''\n",
    "    Adjust nodes in network using backpropagation and ground truth\n",
    "    '''\n",
    "    def adjust_model(self, ground_truth):\n",
    "        # print(self.result, ground_truth)\n",
    "        error = self.result - ground_truth\n",
    "        # print(error)\n",
    "        self.loss = np.dot(error, error) / 2\n",
    "        self.set_output_error(error)\n",
    "        for i in range(len(self.layer_list)-1, -1, -1):\n",
    "            # print(\"in \", i, \"-th layer\")\n",
    "            self.layer_list[i].adjust_weight()\n",
    "\n",
    "    '''\n",
    "    Return network result\n",
    "    '''\n",
    "    def get_result(self):\n",
    "        self.result = self.layer_list[len(self.layer_nums)-1].get_output()\n",
    "        return self.result\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.loss\n",
    "\n",
    "    def get_output_w(self):\n",
    "        w = self.layer_list[len(self.layer_list)-1].get_output_w(0)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fezmbg647700"
   },
   "source": [
    "### Define Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1604123731343,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "NwoN8EKNvsnE"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Layer class for the network model\n",
    "Help model to handle neurons\n",
    "'''\n",
    "class Layer_vec():\n",
    "    '''\n",
    "    Initial layer\n",
    "    @param func - activation function\n",
    "    @param d_func - diviation of activation function\n",
    "    @param node_num - number of nodes in this layer\n",
    "    @param last_layer - last layer's node list\n",
    "    @param is_first - whether this layer is the first layer\n",
    "    '''\n",
    "    def __init__(self, func, d_func, node_num, last_layer, is_first):\n",
    "        # Activation Functions\n",
    "        self.act_func = func                                      # Activation function\n",
    "        self.d_act_func = d_func                                  # Diviation of activate function\n",
    "\n",
    "        # Input definition\n",
    "        if not is_first:\n",
    "            self.i_num = last_layer.get_node_num()               # Number of input node\n",
    "        else:\n",
    "            self.i_num = len(last_layer)                         # Number of input node\n",
    "        self.input_vec = np.full(self.i_num+1, 0.0)              # Initial input passed from\n",
    "        self.input_vec[self.i_num] = 1\n",
    "        self.neuron_num = node_num\n",
    "        self.last_layer = last_layer\n",
    "\n",
    "        # Calculation variables\n",
    "        self.w = np.random.rand(self.i_num+1, node_num)      # Initial weight\n",
    "        self.w = np.full((self.i_num+1, node_num), 0.5)              # Initial input passed from\n",
    "#         print(self.w)\n",
    "        self.bp_vec = np.full(self.neuron_num, 0.0)                   # Recieve value passed from postorier layer\n",
    "        self.is_first = is_first                                  # Set to true if this node is at first layer\n",
    "        self.weighted_input = np.full(self.i_num, 0.0)           # Initial weighted input, use to store the value after the weighted input are sum up\n",
    "        self.result = np.full(self.neuron_num, 0.0)                   # Initial output result, equal to the value after subsituted weighted input into activation function\n",
    "        self.lr_rate = 0.005                                      # Learning rate of the node\n",
    "  \n",
    "    '''\n",
    "    Adjust weights, using backpropagation\n",
    "    For error function, e = y_predict - y_desire\n",
    "    For weight correction, w_n+1 = w_n - delta_w\n",
    "    '''\n",
    "    def adjust_weight(self, lr_rate):\n",
    "        self.lr_rate = lr_rate\n",
    "        # Calculate each weight for the specific previous node\n",
    "        delta = self.bp_vec * self.d_act_func(self.weighted_input)    # Dimation of layer node\n",
    "        delta_w = np.outer(self.input_vec, delta)\n",
    "        if (not self.is_first):\n",
    "            pass_v = np.dot(delta, self.w[0:len(self.w)-1, :].transpose())\n",
    "            self.last_layer.pass_bp(pass_v[0:len(self.input_vec)-1])\n",
    "        self.w = self.w - self.lr_rate * delta_w\n",
    "\n",
    "    def forwrad_pass(self):\n",
    "        if not self.is_first:\n",
    "            self.extract_value()\n",
    "        self.bp_vec = np.full(self.neuron_num, 0.0)      # Set bp value to zero, for later adjustment\n",
    "\n",
    "        # print(self.w, self.input_value)\n",
    "        self.weighted_input = np.dot(self.input_value, self.w)\n",
    "        self.result = self.act_func(self.weighted_input)\n",
    "        return self.result\n",
    "    \n",
    "    '''\n",
    "    Pass backpropagation value back to previous layer\n",
    "    '''\n",
    "    def pass_bp(self, bp_value):\n",
    "        self.bp_vec = bp_value.copy()\n",
    "        \n",
    "    '''\n",
    "    Set input variable, used for first layer which recieve input value\n",
    "    @param x - input value for the network\n",
    "    '''\n",
    "    def set_input(self, x):\n",
    "        self.input_value = x.copy()\n",
    "        if self.is_first:\n",
    "            self.input_value = np.append(self.input_value, 1)\n",
    "            \n",
    "    def extract_value(self):\n",
    "        self.input_value = self.last_layer.get_output()\n",
    "        self.input_value = np.append(self.input_value, 1)\n",
    "\n",
    "    def get_node_num(self):\n",
    "        return self.neuron_num\n",
    "\n",
    "    def set_output_error(self, error):\n",
    "        if self.neuron_num != len(error):\n",
    "            print(\"Output layer and error doesn't match\")\n",
    "            return\n",
    "        self.pass_bp(error)\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.result\n",
    "    def get_output_w(self, i):\n",
    "        return self.node_list[i].w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1447,
     "status": "ok",
     "timestamp": 1604123731675,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "ZmAoCb9d0wTY",
    "outputId": "18442b73-2eec-4039-aabf-4eeb41fdf2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 's round !!!\n",
      "test2 output:  [1.25]\n",
      "1 's round !!!\n",
      "test2 output:  [0.8375]\n",
      "2 's round !!!\n",
      "test2 output:  [0.734375]\n",
      "3 's round !!!\n",
      "test2 output:  [0.70859375]\n",
      "4 's round !!!\n",
      "test2 output:  [0.70214844]\n",
      "5 's round !!!\n",
      "test2 output:  [0.70053711]\n",
      "6 's round !!!\n",
      "test2 output:  [0.70013428]\n",
      "7 's round !!!\n",
      "test2 output:  [0.70003357]\n",
      "8 's round !!!\n",
      "test2 output:  [0.70000839]\n",
      "9 's round !!!\n",
      "test2 output:  [0.7000021]\n",
      "10 's round !!!\n",
      "test2 output:  [0.70000052]\n",
      "11 's round !!!\n",
      "test2 output:  [0.70000013]\n",
      "12 's round !!!\n",
      "test2 output:  [0.70000003]\n",
      "13 's round !!!\n",
      "test2 output:  [0.70000001]\n",
      "14 's round !!!\n",
      "test2 output:  [0.7]\n",
      "15 's round !!!\n",
      "test2 output:  [0.7]\n",
      "16 's round !!!\n",
      "test2 output:  [0.7]\n",
      "17 's round !!!\n",
      "test2 output:  [0.7]\n",
      "18 's round !!!\n",
      "test2 output:  [0.7]\n",
      "19 's round !!!\n",
      "test2 output:  [0.7]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#                     test LAYER block                       #\n",
    "##############################################################\n",
    "\n",
    "lr_rate = 0.5\n",
    "test_l = Layer_vec(ReLU, d_ReLU, 2, [1,2,3], True)\n",
    "test_l2 = Layer_vec(ReLU, d_ReLU, 1, test_l, False)\n",
    "\n",
    "for i in range(20):\n",
    "    print(i, \"'s round !!!\")\n",
    "    test_l.set_input([0.2, 0.1, 0.2])\n",
    "    # print(\"test w: \", test.w)\n",
    "    test_l.forwrad_pass()\n",
    "    # print(\"test output: \", test.get_output())\n",
    "    test_l2.forwrad_pass()\n",
    "    print(\"test2 output: \", test_l2.get_output())\n",
    "    error = test_l2.get_output() - 0.7\n",
    "    test_l2.set_output_error([error])\n",
    "    test_l2.adjust_weight(lr_rate)\n",
    "    test_l.adjust_weight(lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1604123731343,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "NwoN8EKNvsnE"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Layer class for the network model\n",
    "Help model to handle neurons\n",
    "'''\n",
    "class Layer():\n",
    "    '''\n",
    "    Initial layer\n",
    "    @param func - activation function\n",
    "    @param d_func - diviation of activation function\n",
    "    @param node_num - number of nodes in this layer\n",
    "    @param last_layer - last layer's node list\n",
    "    @param is_first - whether this layer is the first layer\n",
    "    '''\n",
    "    def __init__(self, func, d_func, node_num, last_layer, lr_rate, is_first):\n",
    "        # Activation Functions\n",
    "        self.act_func = func                            # Activation function\n",
    "        self.d_act_func = d_func                        # Diviation of activate function\n",
    "\n",
    "        self.last_layer = last_layer                    # Input Layer num\n",
    "        self.node_num = node_num                        # Number of nodes in this layer\n",
    "        self.is_first = is_first                        # Set to true if this node is at first layer\n",
    "        self.lr_rate = lr_rate                          # Learning rate of the node\n",
    "        self.node_result = np.full(self.node_num, 0.0)  # List of all the nodes' output\n",
    "        self.node_list = np.full(self.node_num, None)   # List of all the nodes\n",
    "    #     print(\"in layer, \", self.node_num, self.last_layer)\n",
    "        for i in range(self.node_num):\n",
    "            if isinstance(self.last_layer[0], list):          # If the input is first layer, last layer may be 2-D array, for different input\n",
    "                self.node_list[i] = node(self.act_func, self.d_act_func, self.last_layer[i], self.lr_rate, is_first)       # act_func, d_act_func, input node, is first\n",
    "            else:\n",
    "                self.node_list[i] = node(self.act_func, self.d_act_func, self.last_layer, self.lr_rate, is_first)       # act_func, d_act_func, input node, is first\n",
    "\n",
    "    '''\n",
    "    Adjust weights, using backpropagation\n",
    "    For error function, e = y_predict - y_desire\n",
    "    For weight correction, w_n+1 = w_n - delta_w\n",
    "    '''\n",
    "    def adjust_weight(self):\n",
    "        for i in range(self.node_num):\n",
    "            self.node_list[i].adjust_weight()\n",
    "\n",
    "    def cal_output(self):\n",
    "        # print(\"In layer\")\n",
    "        for i, node in enumerate(self.node_list):\n",
    "            self.node_result[i] = node.cal_output()\n",
    "        # print(self.node_result)\n",
    "\n",
    "    '''\n",
    "    Set input variable, used for first layer which recieve input value\n",
    "    @param x - input value for the network\n",
    "    '''\n",
    "    def set_input(self, x):\n",
    "        self.input_value = x.copy()\n",
    "        for i, node in enumerate(self.node_list):\n",
    "            if isinstance(self.input_value[0], list):          # If the input is first layer, last layer may be 2-D array, for different input\n",
    "                node.set_input(self.input_value[i])\n",
    "            else:\n",
    "                node.set_input(self.input_value)\n",
    "\n",
    "    def get_node_list(self):\n",
    "        return self.node_list.copy()\n",
    "\n",
    "    def set_output_error(self, error):\n",
    "        if self.node_num != len(error):\n",
    "            print(\"Output layer and error doesn't match\")\n",
    "            return\n",
    "        else:\n",
    "            for i, node in enumerate(self.node_list):\n",
    "                node.add_bp(error[i])\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.node_result.copy()\n",
    "    def get_output_w(self, i):\n",
    "        return self.node_list[i].w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y__bH4Dm71un"
   },
   "source": [
    "### Define Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1604123731344,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "bXT_cG8mHYSH"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Node class for the network model\n",
    "Suppose to record input number, out number, weight, and the activation function\n",
    "'''\n",
    "class node():\n",
    "    def __init__(self, func, d_func, i_node, lr_rate, is_first):\n",
    "        # Activation Functions\n",
    "        self.act_func = func                          # Activation function\n",
    "        self.d_act_func = d_func                      # Diviation of activate function\n",
    "\n",
    "        # Input definition\n",
    "        self.i_num = len(i_node)                      # Number of input node\n",
    "        self.i_node = i_node.copy()                   # Input node list\n",
    "        self.input_value = np.full(len(i_node)+1, 0.0)  # Initial input passed from\n",
    "        self.input_value[len(i_node)] = 1\n",
    "\n",
    "        # Calculation variables\n",
    "    #     self.w = np.full(len(i_node)+1, 0.5)            # Initial weight\n",
    "        self.w = np.random.random((len(i_node)+1))            # Initial weight\n",
    "        self.bp_value = 0.0                           # Recieve value passed from next layer\n",
    "        self.is_first = is_first                      # Set to true if this node is at first layer\n",
    "        self.weighted_input = 0.0                     # Initial weighted input, use to store the value after the weighted input are sum up\n",
    "        self.result = 0.0                             # Initial output result, equal to the value after subsituted weighted input into activation function\n",
    "        self.lr_rate = lr_rate                        # Learning rate of the node\n",
    "        # print(self.w, self.input_value)\n",
    "\n",
    "    '''\n",
    "    Calculate output when new input is send into the node\n",
    "    Need to set bp_value to zero, for the adjustment will occur after the calcualtion\n",
    "    '''\n",
    "    def cal_output(self):\n",
    "        if not self.is_first:\n",
    "          self.extract_value()\n",
    "        self.bp_value = 0                     # Set bp value to zero, for later adjustment\n",
    "\n",
    "        # print(self.w, self.input_value)\n",
    "        self.weighted_input = np.dot(self.w, self.input_value)\n",
    "        self.result = self.act_func(self.weighted_input)\n",
    "        return self.result\n",
    "\n",
    "    '''\n",
    "    Adjust weights, using backpropagation\n",
    "    For error function, e = y_predict - y_desire\n",
    "    For weight correction, w_n+1 = w_n - delta_w\n",
    "    '''\n",
    "    def adjust_weight(self):\n",
    "        # Calculate each weight for the specific previous node\n",
    "        for i in range(self.i_num + 1):\n",
    "            tilda = self.bp_value * self.d_act_func(self.weighted_input)\n",
    "            delta_w = tilda * self.input_value[i]\n",
    "            if (not self.is_first) and (i != self.i_num):\n",
    "                self.i_node[i].add_bp(tilda * self.w[i])\n",
    "            self.w[i] -= self.lr_rate * delta_w\n",
    "\n",
    "    '''\n",
    "    Get previous nodes value\n",
    "    '''\n",
    "    def extract_value(self):\n",
    "        # Extract result from previous output\n",
    "        for i, node in enumerate(self.i_node):\n",
    "            self.input_value[i] = node.get_output()\n",
    "\n",
    "    '''\n",
    "    Add backpropagation value to this node\n",
    "    @param pv - passed value from posterior node \n",
    "    '''\n",
    "    def add_bp(self, pv):\n",
    "        self.bp_value += pv\n",
    "\n",
    "    '''\n",
    "    Get result value\n",
    "    '''\n",
    "    def get_output(self):\n",
    "        return self.result\n",
    "\n",
    "    '''\n",
    "    Set input variable, used for first layer which recieve input value\n",
    "    @param x - input value for the network\n",
    "    '''\n",
    "    def set_input(self, x):\n",
    "        self.input_value = x.copy()\n",
    "        if self.is_first:\n",
    "            self.input_value = np.append(self.input_value, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSApFupW7ojO"
   },
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "cellView": "both",
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1604123731345,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "e87aLLFDb-ia"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Activation function for the network\n",
    "'''\n",
    "def test_act_func(x):\n",
    "    return x*11\n",
    "\n",
    "'''\n",
    "ReLU\n",
    "'''\n",
    "def ReLU(x):\n",
    "    x[x<=0] = 0\n",
    "    return x.copy()\n",
    "\n",
    "'''\n",
    "Sigmoid\n",
    "'''\n",
    "def Sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znz66Njx7ueF"
   },
   "source": [
    "### Diviation of Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 1140,
     "status": "ok",
     "timestamp": 1604123731346,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "YgMss65OdtJS"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Diviation of the activation function for the network\n",
    "'''\n",
    "def d_test_act_func(x):\n",
    "    return x+2\n",
    "\n",
    "'''\n",
    "Diviation of ReLU\n",
    "'''\n",
    "def d_ReLU(x):\n",
    "    x[x > 0] = 1\n",
    "    x[x < 0] = 0\n",
    "    return x.copy()\n",
    "\n",
    "'''\n",
    "Diviation of Sigmoid\n",
    "'''\n",
    "def d_Sigmoid(x):\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_2vFmXhZB-a"
   },
   "source": [
    "### Test Node class function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1604123731346,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "Hs6YSl8jbQg-",
    "outputId": "0a2bff16-b95d-4b7a-8306-b41020e069b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 's round !!!\n",
      "test2 output:  0.6171759053310112\n",
      "1 's round !!!\n",
      "test2 output:  0.6975747801574688\n",
      "2 's round !!!\n",
      "test2 output:  0.6999955795656303\n",
      "3 's round !!!\n",
      "test2 output:  0.699999995696245\n",
      "4 's round !!!\n",
      "test2 output:  0.6999999999958164\n",
      "5 's round !!!\n",
      "test2 output:  0.6999999999999958\n",
      "6 's round !!!\n",
      "test2 output:  0.7\n",
      "7 's round !!!\n",
      "test2 output:  0.7\n",
      "8 's round !!!\n",
      "test2 output:  0.7\n",
      "9 's round !!!\n",
      "test2 output:  0.7\n",
      "10 's round !!!\n",
      "test2 output:  0.7\n",
      "11 's round !!!\n",
      "test2 output:  0.7\n",
      "12 's round !!!\n",
      "test2 output:  0.7\n",
      "13 's round !!!\n",
      "test2 output:  0.7\n",
      "14 's round !!!\n",
      "test2 output:  0.7\n",
      "15 's round !!!\n",
      "test2 output:  0.7\n",
      "16 's round !!!\n",
      "test2 output:  0.7\n",
      "17 's round !!!\n",
      "test2 output:  0.7\n",
      "18 's round !!!\n",
      "test2 output:  0.7\n",
      "19 's round !!!\n",
      "test2 output:  0.7\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "#                     test NODE block                       #\n",
    "#############################################################\n",
    "lr_rate = 0.5\n",
    "test= node(ReLU, d_ReLU, [1,2,3], lr_rate, True)       # act_func, d_act_func, input node, is first\n",
    "test2 = node(ReLU, d_ReLU, [test], lr_rate, False)\n",
    "\n",
    "for i in range(20):\n",
    "    print(i, \"'s round !!!\")\n",
    "    test.set_input([0.2, 0.1, 0.2])\n",
    "    # print(\"test w: \", test.w)\n",
    "    test.cal_output()\n",
    "    # print(\"test output: \", test.get_output())\n",
    "    test2.cal_output()\n",
    "    print(\"test2 output: \", test2.get_output())\n",
    "    error = test2.get_output() - 0.7\n",
    "    test2.add_bp(error)\n",
    "    test2.adjust_weight()\n",
    "    test.adjust_weight()\n",
    "\n",
    "    # print(\"test w: \", test.w)\n",
    "    # print(\"test2 w: \", test2.w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg7Rry3AZTia"
   },
   "source": [
    "### Test Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1447,
     "status": "ok",
     "timestamp": 1604123731675,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "ZmAoCb9d0wTY",
    "outputId": "18442b73-2eec-4039-aabf-4eeb41fdf2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 's round !!!\n",
      "test2 output:  [1.61324736]\n",
      "1 's round !!!\n",
      "test2 output:  [0.06102958]\n",
      "2 's round !!!\n",
      "test2 output:  [0.89549628]\n",
      "3 's round !!!\n",
      "test2 output:  [0.64329306]\n",
      "4 's round !!!\n",
      "test2 output:  [0.713997]\n",
      "5 's round !!!\n",
      "test2 output:  [0.69642701]\n",
      "6 's round !!!\n",
      "test2 output:  [0.70090361]\n",
      "7 's round !!!\n",
      "test2 output:  [0.69977095]\n",
      "8 's round !!!\n",
      "test2 output:  [0.70005803]\n",
      "9 's round !!!\n",
      "test2 output:  [0.6999853]\n",
      "10 's round !!!\n",
      "test2 output:  [0.70000373]\n",
      "11 's round !!!\n",
      "test2 output:  [0.69999906]\n",
      "12 's round !!!\n",
      "test2 output:  [0.70000024]\n",
      "13 's round !!!\n",
      "test2 output:  [0.69999994]\n",
      "14 's round !!!\n",
      "test2 output:  [0.70000002]\n",
      "15 's round !!!\n",
      "test2 output:  [0.7]\n",
      "16 's round !!!\n",
      "test2 output:  [0.7]\n",
      "17 's round !!!\n",
      "test2 output:  [0.7]\n",
      "18 's round !!!\n",
      "test2 output:  [0.7]\n",
      "19 's round !!!\n",
      "test2 output:  [0.7]\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#                     test LAYER block                       #\n",
    "##############################################################\n",
    "\n",
    "lr_rate = 0.5\n",
    "test_l = Layer(ReLU, d_ReLU, 2, [1,2,3], lr_rate, True)\n",
    "test_l2 = Layer(ReLU, d_ReLU, 1, test_l.get_node_list().copy(), lr_rate, False)\n",
    "\n",
    "for i in range(20):\n",
    "    print(i, \"'s round !!!\")\n",
    "    test_l.set_input([0.2, 0.1, 0.2])\n",
    "    # print(\"test w: \", test.w)\n",
    "    test_l.cal_output()\n",
    "    # print(\"test output: \", test.get_output())\n",
    "    test_l2.cal_output()\n",
    "    print(\"test2 output: \", test_l2.get_output())\n",
    "    error = test_l2.get_output() - 0.7\n",
    "    test_l2.set_output_error([error])\n",
    "    test_l2.adjust_weight()\n",
    "    test_l.adjust_weight()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN3Wu8TfkxMB"
   },
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1426,
     "status": "ok",
     "timestamp": 1604123731678,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "0ADV2VnBk5Ws",
    "outputId": "ae0f2383-1b6c-4fa3-d041-ec67d450b3d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 's round !!!\n",
      "test_m output:  [1.76569813]\n",
      "1 's round !!!\n",
      "test_m output:  [0.]\n",
      "2 's round !!!\n",
      "test_m output:  [0.]\n",
      "3 's round !!!\n",
      "test_m output:  [0.]\n",
      "4 's round !!!\n",
      "test_m output:  [0.]\n",
      "5 's round !!!\n",
      "test_m output:  [0.]\n",
      "6 's round !!!\n",
      "test_m output:  [0.]\n",
      "7 's round !!!\n",
      "test_m output:  [0.]\n",
      "8 's round !!!\n",
      "test_m output:  [0.]\n",
      "9 's round !!!\n",
      "test_m output:  [0.]\n",
      "10 's round !!!\n",
      "test_m output:  [0.]\n",
      "11 's round !!!\n",
      "test_m output:  [0.]\n",
      "12 's round !!!\n",
      "test_m output:  [0.]\n",
      "13 's round !!!\n",
      "test_m output:  [0.]\n",
      "14 's round !!!\n",
      "test_m output:  [0.]\n",
      "15 's round !!!\n",
      "test_m output:  [0.]\n",
      "16 's round !!!\n",
      "test_m output:  [0.]\n",
      "17 's round !!!\n",
      "test_m output:  [0.]\n",
      "18 's round !!!\n",
      "test_m output:  [0.]\n",
      "19 's round !!!\n",
      "test_m output:  [0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.20920424,  0.5312474 ,  0.07663143, -0.23165184])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################\n",
    "#                     test MODEL block                       #\n",
    "##############################################################\n",
    "\n",
    "lr_rate = 0.5\n",
    "layer_nums = [2, 1]\n",
    "layer_input = [[1, 1], [1], [1]]\n",
    "test_m = Model(ReLU, d_ReLU, layer_nums, layer_input, lr_rate)\n",
    "input_data = [[0.2, 0.1], [0.1], [0.2]]\n",
    "ground_truth = 0.7\n",
    "for i in range(20):\n",
    "    print(i, \"'s round !!!\")\n",
    "    test_m.cal_network(input_data)\n",
    "    print(\"test_m output: \", test_m.get_result())\n",
    "    test_m.adjust_model(ground_truth)\n",
    "test_m.get_loss()\n",
    "test_m.get_output_w()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4 6]\n",
      " [1 2 3]]\n",
      "[28 14]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[    1     4 10000]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2,1])\n",
    "c = np.outer(b,a)\n",
    "print(c)\n",
    "print(np.dot(c, a))\n",
    "print(np.zeros([2,3]))\n",
    "a[a>2] = 100\n",
    "print(a*a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZ5Ez+SCmycxN0mfXR93qW",
   "collapsed_sections": [
    "RSApFupW7ojO",
    "znz66Njx7ueF",
    "7_2vFmXhZB-a",
    "Fg7Rry3AZTia"
   ],
   "name": "NN_HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
