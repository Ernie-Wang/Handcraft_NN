{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install import-ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eI-4B9Dubcl"
   },
   "source": [
    "## Dataset Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9CBa4cVgtGJ6"
   },
   "outputs": [],
   "source": [
    "# Total 9 data, use 4 bits\n",
    "workclass_dict = {\n",
    "                  \"bits\": 4,\n",
    "                  \"Private\": 0,\n",
    "                  \"Self-emp-not-inc\": 1,\n",
    "                  \"Self-emp-inc\": 2,\n",
    "                  \"Federal-gov\": 3,\n",
    "                  \"Local-gov\": 4,\n",
    "                  \"State-gov\": 5,\n",
    "                  \"Without-pay\": 6,\n",
    "                  \"Never-worked\": 7,\n",
    "                  \"?\": 8\n",
    "                  }\n",
    "\n",
    "# Total 17 data, use 5 bits\n",
    "edu_dict = {\n",
    "            \"bits\": 5,\n",
    "            \"Bachelors\": 0,\n",
    "            \"Some-college\": 1,\n",
    "            \"11th\": 2,\n",
    "            \"HS-grad\": 3,\n",
    "            \"Prof-school\": 4,\n",
    "            \"Assoc-acdm\": 5,\n",
    "            \"Assoc-voc\": 6,\n",
    "            \"9th\": 7,\n",
    "            \"7th-8th\": 8,\n",
    "            \"12th\": 9,\n",
    "            \"Masters\": 10,\n",
    "            \"1st-4th\": 11,\n",
    "            \"10th\": 12,\n",
    "            \"Doctorate\": 13,\n",
    "            \"5th-6th\": 14,\n",
    "            \"Preschool\": 15,\n",
    "            \"?\": 16\n",
    "            }\n",
    "\n",
    "# Total 8 data, use 3 bits\n",
    "marital_dict = {\n",
    "                \"bits\": 3,\n",
    "                \"Married-civ-spouse\": 0,\n",
    "                \"Divorced\": 1,\n",
    "                \"Never-married\": 2,\n",
    "                \"Separated\": 3,\n",
    "                \"Widowed\": 4,\n",
    "                \"Married-spouse-absent\": 5,\n",
    "                \"Married-AF-spouse\": 6,\n",
    "                \"?\": 7\n",
    "              }\n",
    "\n",
    "# Total 15 data, use 4 bits\n",
    "occup_dict = {\n",
    "              \"bits\": 4,\n",
    "              \"Tech-support\": 0,\n",
    "              \"Craft-repair\": 1,\n",
    "              \"Other-service\": 2,\n",
    "              \"Sales\": 3,\n",
    "              \"Exec-managerial\": 4,\n",
    "              \"Prof-specialty\": 5,\n",
    "              \"Handlers-cleaners\": 6,\n",
    "              \"Machine-op-inspct\": 7,\n",
    "              \"Adm-clerical\": 8,\n",
    "              \"Farming-fishing\": 9,\n",
    "              \"Transport-moving\": 10,\n",
    "              \"Priv-house-serv\": 11,\n",
    "              \"Protective-serv\": 12,\n",
    "              \"Armed-Forces\": 13,\n",
    "              \"?\": 14\n",
    "              }\n",
    "\n",
    "# Total 7 data, use 3 bits\n",
    "relation_dict = {\n",
    "                \"bits\": 3,\n",
    "                \"Wife\": 0,\n",
    "                \"Own-child\": 1,\n",
    "                \"Husband\": 2,\n",
    "                \"Not-in-family\": 3,\n",
    "                \"Other-relative\": 4,\n",
    "                \"Unmarried\": 5,\n",
    "                \"Ether-relative\": 6,\n",
    "                \"?\": 7,\n",
    "                }\n",
    "\n",
    "# Total 6 data, use 3 bits\n",
    "race_dict = {\n",
    "            \"bits\": 3,\n",
    "            \"White\": 0,\n",
    "            \"Asian-Pac-Islander\": 1,\n",
    "            \"Amer-Indian-Eskimo\": 2,\n",
    "            \"Other\": 3,\n",
    "            \"Black\": 4,\n",
    "            \"?\": 5\n",
    "            }\n",
    "\n",
    "# Total 2 data, use 1 bits\n",
    "sex_dict = {\n",
    "            \"bits\": 1,\n",
    "            \"Female\": 0,\n",
    "            \"Male\": 1\n",
    "            }\n",
    "\n",
    "# Total 42 data, use 6 bits\n",
    "country_dict = {\n",
    "                \"bits\": 6,\n",
    "                \"United-States\": 0,\n",
    "                \"Cambodia\": 1,\n",
    "                \"England\": 2,\n",
    "                \"Puerto-Rico\": 3,\n",
    "                \"Canada\": 4,\n",
    "                \"Germany\": 5,\n",
    "                \"Outlying-US(Guam-USVI-etc)\": 6,\n",
    "                \"India\": 7,\n",
    "                \"Japan\": 8,\n",
    "                \"Greece\": 9,\n",
    "                \"South\": 10,\n",
    "                \"China\": 11,\n",
    "                \"Cuba\": 12,\n",
    "                \"Iran\": 13,\n",
    "                \"Honduras\": 14,\n",
    "                \"Philippines\": 15,\n",
    "                \"Italy\": 16,\n",
    "                \"Poland\": 17,\n",
    "                \"Jamaica\": 18,\n",
    "                \"Vietnam\": 19,\n",
    "                \"Mexico\": 20,\n",
    "                \"Portugal\": 21,\n",
    "                \"Ireland\": 22,\n",
    "                \"France\": 23,\n",
    "                \"Dominican-Republic\": 24,\n",
    "                \"Laos\": 25,\n",
    "                \"Ecuador\": 26,\n",
    "                \"Taiwan\": 27,\n",
    "                \"Haiti\": 28,\n",
    "                \"Columbia\": 29,\n",
    "                \"Hungary\": 30,\n",
    "                \"Guatemala\": 31,\n",
    "                \"Nicaragua\": 32,\n",
    "                \"Scotland\": 33,\n",
    "                \"Thailand\": 34,\n",
    "                \"Yugoslavia\": 35,\n",
    "                \"El-Salvador\": 36,\n",
    "                \"Trinadad&Tobago\": 37,\n",
    "                \"Peru\": 38,\n",
    "                \"Hong\": 39,\n",
    "                \"Holand-Netherlands\": 40,\n",
    "                \"?\": 41\n",
    "                }\n",
    "\n",
    "# Total 2 data, use 1 bits\n",
    "train_result_dict = {\n",
    "                \"bits\": 1,\n",
    "                \"<=50K\": 0,\n",
    "                \">50K\": 1\n",
    "                }\n",
    "\n",
    "# Total 2 data, use 1 bits\n",
    "test_result_dict = {\n",
    "                \"bits\": 1,\n",
    "                \"<=50K.\": 0,\n",
    "                \">50K.\": 1\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmr3ycLG2ZcX"
   },
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tPaU25U2c2l",
    "outputId": "bd6aab55-3f73-442c-aa49-3e70575856c6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import import_ipynb\n",
    "from importnb import Notebook\n",
    "# with Notebook(): \n",
    "#     import NN_HW3 as Nn\n",
    "from tqdm import tqdm, trange, notebook\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH5Q0QyZ97qs"
   },
   "source": [
    "## Data Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rMaZp5-4k2Zj"
   },
   "outputs": [],
   "source": [
    "tag_name = [\"age\", \"workclass\", \"fnlwgt\", \"edu\", \"education-num\", \"marital\", \"occup\", \"relation\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"country\", \"result\"]\n",
    "data_size = [7, 4, 21, 5, 6, 3, 4, 3, 3, 1, 20, 13, 7, 6, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8daLbDTlLCJ"
   },
   "source": [
    "## Read Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nYNcdCW38-g4"
   },
   "outputs": [],
   "source": [
    "def read_data(filename, name_col, i_sep, result_dict):\n",
    "  data_file = pd.read_csv(filename, header=None, names=name_col, sep=i_sep)\n",
    "  preprocess_data = np.empty(shape=(data_file.shape[0], data_file.shape[1]), dtype=\"U32\")\n",
    "  for i in range(data_file.shape[0]):\n",
    "  # for i in range(4):\n",
    "    row = data_file.iloc[i]\n",
    "    preprocess_data[i][0] = np.binary_repr(row[\"age\"], 7)\n",
    "    preprocess_data[i][1] = np.binary_repr( workclass_dict[row[\"workclass\"]], workclass_dict[\"bits\"] )\n",
    "    preprocess_data[i][2] = np.binary_repr(row[\"fnlwgt\"], 21)\n",
    "    preprocess_data[i][3] = np.binary_repr( edu_dict[row[\"edu\"]], edu_dict[\"bits\"] )\n",
    "    preprocess_data[i][4] = np.binary_repr(row[\"education-num\"], 6)\n",
    "    preprocess_data[i][5] = np.binary_repr( marital_dict[row[\"marital\"]], marital_dict[\"bits\"] )\n",
    "    preprocess_data[i][6] = np.binary_repr( occup_dict[row[\"occup\"]], occup_dict[\"bits\"] )\n",
    "    preprocess_data[i][7] = np.binary_repr( relation_dict[row[\"relation\"]], relation_dict[\"bits\"] )\n",
    "    preprocess_data[i][8] = np.binary_repr( race_dict[row[\"race\"]], race_dict[\"bits\"] )\n",
    "    preprocess_data[i][9] = sex_dict[row[\"sex\"]]\n",
    "    preprocess_data[i][10] = np.binary_repr(row[\"capital-gain\"], 20)\n",
    "    preprocess_data[i][11] = np.binary_repr(row[\"capital-loss\"], 13)\n",
    "    preprocess_data[i][12] = np.binary_repr(row[\"hours-per-week\"], 7)\n",
    "    preprocess_data[i][13] = np.binary_repr( country_dict[row[\"country\"]], country_dict[\"bits\"] )\n",
    "    preprocess_data[i][14] = result_dict[row[\"result\"]]\n",
    "  return preprocess_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oIA-pUo97IU",
    "outputId": "cc0534b4-3421-4733-c7cb-09c59a52f263"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airobot109/anaconda3/envs/nn_class/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_data = read_data('./adult/adult.data', tag_name, \", \", train_result_dict)\n",
    "test_data = read_data('./adult/adult.test', tag_name, \", \", test_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8zLQ9VJGi4n",
    "outputId": "c3d37a11-c123-498b-fc63-9a36e94c7a90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "0100111\n",
      "7\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "a = train_data[0][0]\n",
    "print(a)\n",
    "# a = train_data[0][1].astype(int)\n",
    "# a = np.fromstring(a, dtype=int)\n",
    "a = np.array(list(a), dtype=np.int)\n",
    "print(len(a))\n",
    "for i in range(len(a)):\n",
    "  print(type(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-QysukoaafK5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input(x):\n",
    "    ans = []\n",
    "    for i in x:\n",
    "        i = np.array(list(i), dtype=np.int)\n",
    "        ans = np.append(ans, list(i))\n",
    "#     ans_1d = []\n",
    "    \n",
    "#     for i in ans:\n",
    "#         ans_1d = np.append(ans_1d, i, 0)\n",
    "    return ans.copy()\n",
    "\n",
    "ans = preprocess_input(train_data[0])\n",
    "ans1 = preprocess_input(train_data[1])\n",
    "print(ans)\n",
    "print(ans1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(model, input_arr, layer_num):\n",
    "    for i, num in enumerate(layer_num):\n",
    "        if i == 0:\n",
    "            model.layer_list.append( Nn.Layer_vec(Nn.ReLU, Nn.d_ReLU, num, input_arr, True) )\n",
    "        elif i == len(layer_num)-2:\n",
    "            model.layer_list.append( Nn.Layer_vec(Nn.Sigmoid, Nn.d_Sigmoid, num, model.layer_list[i-1], False) )\n",
    "        else:\n",
    "            model.layer_list.append( Nn.Layer_vec(Nn.ReLU, Nn.d_ReLU, num, model.layer_list[i-1], False) )\n",
    "#     model.layer_list.append( Nn.Softmax_Output(model.layer_list[len(model.layer_list)-1]) )\n",
    "    print(model.layer_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 's round !!!\n",
      "test2 output:  [1.16107354]\n",
      "1 's round !!!\n",
      "test2 output:  [0.71867908]\n",
      "2 's round !!!\n",
      "test2 output:  [0.70348081]\n",
      "3 's round !!!\n",
      "test2 output:  [0.7006627]\n",
      "4 's round !!!\n",
      "test2 output:  [0.70012666]\n",
      "5 's round !!!\n",
      "test2 output:  [0.70002423]\n",
      "6 's round !!!\n",
      "test2 output:  [0.70000463]\n",
      "7 's round !!!\n",
      "test2 output:  [0.70000089]\n",
      "8 's round !!!\n",
      "test2 output:  [0.70000017]\n",
      "9 's round !!!\n",
      "test2 output:  [0.70000003]\n",
      "10 's round !!!\n",
      "test2 output:  [0.70000001]\n",
      "11 's round !!!\n",
      "test2 output:  [0.7]\n",
      "12 's round !!!\n",
      "test2 output:  [0.7]\n",
      "13 's round !!!\n",
      "test2 output:  [0.7]\n",
      "14 's round !!!\n",
      "test2 output:  [0.7]\n",
      "15 's round !!!\n",
      "test2 output:  [0.7]\n",
      "16 's round !!!\n",
      "test2 output:  [0.7]\n",
      "17 's round !!!\n",
      "test2 output:  [0.7]\n",
      "18 's round !!!\n",
      "test2 output:  [0.7]\n",
      "19 's round !!!\n",
      "test2 output:  [0.7]\n",
      "[<NN_HW3_sm.Layer_vec object at 0x7f82078c3208>, <NN_HW3_sm.Layer_vec object at 0x7f82076179b0>, <NN_HW3_sm.Layer_vec object at 0x7f82076d32b0>, <NN_HW3_sm.Layer_vec object at 0x7f8218771860>]\n",
      "1 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a64e1ef01e4be8bd775e506fb0d652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dabf6a830a34d50ade490ea41af6d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-557ad94659e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mtrain_err_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mtrain_err_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtrain_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#                         MODEL block                        #\n",
    "##############################################################\n",
    "\n",
    "with Notebook(): \n",
    "    import NN_HW3_sm as Nn\n",
    "# lr_rate = 0.00009\n",
    "epochs = 500\n",
    "\n",
    "lr_rate = 0.00001\n",
    "layer_nums = [100, 40, 5, 2]\n",
    "# layer_nums = [train_data.shape[1]-1, 7, 1]\n",
    "layer_input = preprocess_input(train_data[0])\n",
    "layer_input = layer_input[:len(layer_input)-1]\n",
    "test_m = Nn.Model(layer_nums, construct_model, layer_input, lr_rate)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "output_node_w = [[]]\n",
    "output_node_w = np.array([test_m.get_output_w()])\n",
    "# print(i, \"'s data !!!\")\n",
    "# p_data = preprocess_input(train_data[0])\n",
    "# test_m.cal_network(p_data[:14])\n",
    "# ans = test_m.get_result()\n",
    "# test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "# error.append(test_m.get_loss())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_err_cnt = 0\n",
    "    train_error = []\n",
    "    print(epoch+1, \"/\", epochs, \"epochs\")\n",
    "    train_progress = notebook.tqdm(total=len(train_data), desc=\"Training\")\n",
    "    test_progress = notebook.tqdm(total=len(test_data), desc=\"Testing\")\n",
    "    for i, input_data in enumerate(train_data):\n",
    "        # print(i, \"'s data !!!\")\n",
    "        train_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans = test_m.get_result()\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            if abs(ans - p_data[len(p_data)-1][0]) > 0.5:\n",
    "                train_err_cnt += 1\n",
    "        else:\n",
    "            if abs(ans - p_data[len(p_data)-1]) > 0.5:\n",
    "                train_err_cnt += 1\n",
    "        train_error.append(test_m.get_loss())\n",
    "        # Adjust model weights\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "        else:\n",
    "            test_m.adjust_model(p_data[len(p_data)-1])\n",
    "    output_node_w = np.append(output_node_w, [test_m.get_output_w()], 0)\n",
    "        \n",
    "    train_loss.append(np.average(train_error))\n",
    "    train_acc.append(1 - train_err_cnt/len(train_data) )\n",
    "    print(\"Train loss: \", np.average(train_error), \", acc = \", (1-train_err_cnt/len(train_data)) * 100, \"%\")\n",
    "    test_err_cnt = 0\n",
    "    test_error = []\n",
    "    for i, input_data in enumerate(test_data):\n",
    "        test_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans = test_m.get_result()\n",
    "        error = 0\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            error = ans - p_data[len(p_data)-1][0]\n",
    "            if abs(error) > 0.5:\n",
    "                test_err_cnt += 1\n",
    "        else:\n",
    "            error = ans - p_data[len(p_data)-1]\n",
    "            if abs(error) > 0.5:\n",
    "                test_err_cnt += 1\n",
    "        test_error.append(np.dot(error, error) / 2)\n",
    "        \n",
    "    test_loss.append(np.average(test_error))\n",
    "    test_acc.append(1 - test_err_cnt/len(test_data) )\n",
    "    print(\"Test loss: \", np.average(test_error), \", acc = \", (1-test_err_cnt/len(test_data)) * 100, \"%\")\n",
    "    print()\n",
    "test_m.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# print(output_node_w)\n",
    "x= np.arange(0,len(output_node_w))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, output_node_w[:,:,0])\n",
    "plt.title('Weight Change')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"value\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "x= np.arange(0,len(train_acc))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, train_acc, color='Blue', label='Train')\n",
    "plt.plot(x, test_acc, color='Orange', label='Validation')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) \n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(x, train_loss, color='Blue', label='Train')\n",
    "plt.plot(x, test_loss, color='Orange', label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Loss\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n0TeSbnPzQv"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                         MODEL block                        #\n",
    "##############################################################\n",
    "\n",
    "with Notebook(): \n",
    "    import NN_HW3 as Nn\n",
    "lr_rate = 0.1\n",
    "epochs = 500\n",
    "layer_nums = [train_data.shape[1]-1, 7, 1]\n",
    "layer_input = preprocess_input(train_data[0])\n",
    "layer_input = layer_input[:len(layer_input)-1]\n",
    "test_m = Nn.Model(Nn.Sigmoid, Nn.d_Sigmoid, layer_nums, layer_input, lr_rate)  # Correct when creating\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "output_node_w = [[]]\n",
    "output_node_w = np.array([test_m.get_output_w()])\n",
    "# print(i, \"'s data !!!\")\n",
    "# p_data = preprocess_input(train_data[0])\n",
    "# test_m.cal_network(p_data[:14])\n",
    "# ans = test_m.get_result()\n",
    "# test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "# error.append(test_m.get_loss())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_err_cnt = 0\n",
    "    train_error = []\n",
    "    print(epoch+1, \"/\", epochs, \"epochs\")\n",
    "    train_progress = notebook.tqdm(total=len(train_data), desc=\"Training\")\n",
    "    test_progress = notebook.tqdm(total=len(test_data), desc=\"Testing\")\n",
    "    for i, input_data in enumerate(train_data):\n",
    "        # print(i, \"'s data !!!\")\n",
    "        train_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans = test_m.get_result()\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            if abs(ans - p_data[len(p_data)-1][0]) > 0.5:\n",
    "                train_err_cnt += 1\n",
    "        else:\n",
    "            if abs(ans - p_data[len(p_data)-1]) > 0.5:\n",
    "                train_err_cnt += 1\n",
    "        train_error.append(test_m.get_loss())\n",
    "        # Adjust model weights\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "        else:\n",
    "            test_m.adjust_model(p_data[len(p_data)-1])\n",
    "    output_node_w = np.append(output_node_w, [test_m.get_output_w()], 0)\n",
    "        \n",
    "    train_loss.append(np.average(train_error))\n",
    "    train_acc.append(1 - train_err_cnt/len(train_data) )\n",
    "    print(\"Train loss: \", np.average(train_error), \", acc = \", (1-train_err_cnt/len(train_data)) * 100, \"%\")\n",
    "    test_err_cnt = 0\n",
    "    test_error = []\n",
    "    for i, input_data in enumerate(test_data):\n",
    "        test_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans = test_m.get_result()\n",
    "        error = 0\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            error = ans - p_data[len(p_data)-1][0]\n",
    "            if abs(error) > 0.5:\n",
    "                test_err_cnt += 1\n",
    "        else:\n",
    "            error = ans - p_data[len(p_data)-1]\n",
    "            if abs(error) > 0.5:\n",
    "                test_err_cnt += 1\n",
    "        test_error.append(np.dot(error, error) / 2)\n",
    "        \n",
    "    test_loss.append(np.average(test_error))\n",
    "    test_acc.append(1 - test_err_cnt/len(test_data) )\n",
    "    print(\"Test loss: \", np.average(test_error), \", acc = \", (1-test_err_cnt/len(test_data)) * 100, \"%\")\n",
    "    print()\n",
    "test_m.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "x= np.arange(0,len(output_node_w))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, output_node_w)\n",
    "plt.title('Weight Change')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"value\") \n",
    "\n",
    "# print(output_node_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaBqKsYpgaoZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "x= np.arange(0,len(train_acc))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, train_acc, color='Blue', label='Train')\n",
    "plt.plot(x, test_acc, color='Orange', label='Validation')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) \n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(x, train_loss, color='Blue', label='Train')\n",
    "plt.plot(x, test_loss, color='Orange', label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Loss\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RcxY2V6ijph"
   },
   "outputs": [],
   "source": [
    "error_cnt = 0\n",
    "for i, input_data in enumerate(test_data):\n",
    "  # print(i, \"'s data !!!\")\n",
    "  # print(input_data)\n",
    "  p_data = preprocess_input(input_data)\n",
    "  # print(p_data)\n",
    "  test_m.cal_network(p_data[:14])\n",
    "  ans = test_m.get_result()\n",
    "  # print(i ,test_m.get_loss())\n",
    "  # print(ans, p_data[len(p_data)-1][0])\n",
    "  if abs(ans - p_data[len(p_data)-1][0]) > 0.5:\n",
    "    error_cnt += 1\n",
    "  # test_m.adjust_model(p_data[len(p_data)-1])\n",
    "  # error.append(test_m.get_loss())\n",
    "# test_m.get_loss()\n",
    "# print(i, \"'s data !!!\")\n",
    "input_data = test_data[0]\n",
    "# print(input_data)\n",
    "p_data = preprocess_input(input_data)[:14]\n",
    "# print(p_data)\n",
    "test_m.cal_network(p_data)\n",
    "ans = test_m.get_result()\n",
    "# print(i ,test_m.get_loss())\n",
    "if abs(ans - p_data[len(p_data)-1][0]) > 0.5:\n",
    "  error_cnt += 1\n",
    "print(error_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C58cmj8kj7xy"
   },
   "outputs": [],
   "source": [
    "print(len(test_data))\n",
    "print(p_data[len(p_data)-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6N3g0aYAzUd"
   },
   "outputs": [],
   "source": [
    "a = [[1, 3], [2, 4]]\n",
    "b = [1, 3]\n",
    "for i in a:\n",
    "  print(len(i))\n",
    "w = 2*np.random.random((10))\n",
    "print(w)\n",
    "# for i in b:\n",
    "#   print(len(i))\n",
    "# print(len(a.shape))\n",
    "# print(len(b.shape))\n",
    "print(np.tile(b, (3,)))\n",
    "# preprocess_data = np.zeros((0,7))\n",
    "# print(preprocess_data)\n",
    "# preprocess_data = np.append(preprocess_data, [[0,1,2,3,4,5,6]], 0)\n",
    "# preprocess_data = np.append(preprocess_data, [[1,1,2,3,4,5,6]], 0)\n",
    "# print(preprocess_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0eI-4B9Dubcl"
   ],
   "name": "HW3_Q1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
