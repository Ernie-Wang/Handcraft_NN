{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install import-ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eI-4B9Dubcl"
   },
   "source": [
    "## Dataset Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9CBa4cVgtGJ6"
   },
   "outputs": [],
   "source": [
    "# Total 9 data, use 4 bits\n",
    "workclass_dict = {\n",
    "                  \"bits\": 4,\n",
    "                  \"Private\": 0,\n",
    "                  \"Self-emp-not-inc\": 1,\n",
    "                  \"Self-emp-inc\": 2,\n",
    "                  \"Federal-gov\": 3,\n",
    "                  \"Local-gov\": 4,\n",
    "                  \"State-gov\": 5,\n",
    "                  \"Without-pay\": 6,\n",
    "                  \"Never-worked\": 7,\n",
    "                  \"?\": 8\n",
    "                  }\n",
    "\n",
    "# Total 17 data, use 5 bits\n",
    "edu_dict = {\n",
    "            \"bits\": 5,\n",
    "            \"Bachelors\": 0,\n",
    "            \"Some-college\": 1,\n",
    "            \"11th\": 2,\n",
    "            \"HS-grad\": 3,\n",
    "            \"Prof-school\": 4,\n",
    "            \"Assoc-acdm\": 5,\n",
    "            \"Assoc-voc\": 6,\n",
    "            \"9th\": 7,\n",
    "            \"7th-8th\": 8,\n",
    "            \"12th\": 9,\n",
    "            \"Masters\": 10,\n",
    "            \"1st-4th\": 11,\n",
    "            \"10th\": 12,\n",
    "            \"Doctorate\": 13,\n",
    "            \"5th-6th\": 14,\n",
    "            \"Preschool\": 15,\n",
    "            \"?\": 16\n",
    "            }\n",
    "\n",
    "# Total 8 data, use 3 bits\n",
    "marital_dict = {\n",
    "                \"bits\": 3,\n",
    "                \"Married-civ-spouse\": 0,\n",
    "                \"Divorced\": 1,\n",
    "                \"Never-married\": 2,\n",
    "                \"Separated\": 3,\n",
    "                \"Widowed\": 4,\n",
    "                \"Married-spouse-absent\": 5,\n",
    "                \"Married-AF-spouse\": 6,\n",
    "                \"?\": 7\n",
    "              }\n",
    "\n",
    "# Total 15 data, use 4 bits\n",
    "occup_dict = {\n",
    "              \"bits\": 4,\n",
    "              \"Tech-support\": 0,\n",
    "              \"Craft-repair\": 1,\n",
    "              \"Other-service\": 2,\n",
    "              \"Sales\": 3,\n",
    "              \"Exec-managerial\": 4,\n",
    "              \"Prof-specialty\": 5,\n",
    "              \"Handlers-cleaners\": 6,\n",
    "              \"Machine-op-inspct\": 7,\n",
    "              \"Adm-clerical\": 8,\n",
    "              \"Farming-fishing\": 9,\n",
    "              \"Transport-moving\": 10,\n",
    "              \"Priv-house-serv\": 11,\n",
    "              \"Protective-serv\": 12,\n",
    "              \"Armed-Forces\": 13,\n",
    "              \"?\": 14\n",
    "              }\n",
    "\n",
    "# Total 7 data, use 3 bits\n",
    "relation_dict = {\n",
    "                \"bits\": 3,\n",
    "                \"Wife\": 0,\n",
    "                \"Own-child\": 1,\n",
    "                \"Husband\": 2,\n",
    "                \"Not-in-family\": 3,\n",
    "                \"Other-relative\": 4,\n",
    "                \"Unmarried\": 5,\n",
    "                \"Ether-relative\": 6,\n",
    "                \"?\": 7,\n",
    "                }\n",
    "\n",
    "# Total 6 data, use 3 bits\n",
    "race_dict = {\n",
    "            \"bits\": 3,\n",
    "            \"White\": 0,\n",
    "            \"Asian-Pac-Islander\": 1,\n",
    "            \"Amer-Indian-Eskimo\": 2,\n",
    "            \"Other\": 3,\n",
    "            \"Black\": 4,\n",
    "            \"?\": 5\n",
    "            }\n",
    "\n",
    "# Total 2 data, use 1 bits\n",
    "sex_dict = {\n",
    "            \"bits\": 1,\n",
    "            \"Female\": 0,\n",
    "            \"Male\": 1\n",
    "            }\n",
    "\n",
    "# Total 42 data, use 6 bits\n",
    "country_dict = {\n",
    "                \"bits\": 6,\n",
    "                \"United-States\": 0,\n",
    "                \"Cambodia\": 1,\n",
    "                \"England\": 2,\n",
    "                \"Puerto-Rico\": 3,\n",
    "                \"Canada\": 4,\n",
    "                \"Germany\": 5,\n",
    "                \"Outlying-US(Guam-USVI-etc)\": 6,\n",
    "                \"India\": 7,\n",
    "                \"Japan\": 8,\n",
    "                \"Greece\": 9,\n",
    "                \"South\": 10,\n",
    "                \"China\": 11,\n",
    "                \"Cuba\": 12,\n",
    "                \"Iran\": 13,\n",
    "                \"Honduras\": 14,\n",
    "                \"Philippines\": 15,\n",
    "                \"Italy\": 16,\n",
    "                \"Poland\": 17,\n",
    "                \"Jamaica\": 18,\n",
    "                \"Vietnam\": 19,\n",
    "                \"Mexico\": 20,\n",
    "                \"Portugal\": 21,\n",
    "                \"Ireland\": 22,\n",
    "                \"France\": 23,\n",
    "                \"Dominican-Republic\": 24,\n",
    "                \"Laos\": 25,\n",
    "                \"Ecuador\": 26,\n",
    "                \"Taiwan\": 27,\n",
    "                \"Haiti\": 28,\n",
    "                \"Columbia\": 29,\n",
    "                \"Hungary\": 30,\n",
    "                \"Guatemala\": 31,\n",
    "                \"Nicaragua\": 32,\n",
    "                \"Scotland\": 33,\n",
    "                \"Thailand\": 34,\n",
    "                \"Yugoslavia\": 35,\n",
    "                \"El-Salvador\": 36,\n",
    "                \"Trinadad&Tobago\": 37,\n",
    "                \"Peru\": 38,\n",
    "                \"Hong\": 39,\n",
    "                \"Holand-Netherlands\": 40,\n",
    "                \"?\": 41\n",
    "                }\n",
    "\n",
    "# Total 2 data, use 1 bits\n",
    "train_result_dict = {\n",
    "                \"bits\": 1,\n",
    "                \"<=50K\": 0,\n",
    "                \">50K\": 1\n",
    "                }\n",
    "\n",
    "# Total 2 data, use 1 bits\n",
    "test_result_dict = {\n",
    "                \"bits\": 1,\n",
    "                \"<=50K.\": 0,\n",
    "                \">50K.\": 1\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmr3ycLG2ZcX"
   },
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tPaU25U2c2l",
    "outputId": "bd6aab55-3f73-442c-aa49-3e70575856c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 's round !!!\n",
      "test2 output:  [1.60284052]\n",
      "1 's round !!!\n",
      "test2 output:  [0.47371384]\n",
      "2 's round !!!\n",
      "test2 output:  [0.68660755]\n",
      "3 's round !!!\n",
      "test2 output:  [0.6993488]\n",
      "4 's round !!!\n",
      "test2 output:  [0.69996923]\n",
      "5 's round !!!\n",
      "test2 output:  [0.69999855]\n",
      "6 's round !!!\n",
      "test2 output:  [0.69999993]\n",
      "7 's round !!!\n",
      "test2 output:  [0.7]\n",
      "8 's round !!!\n",
      "test2 output:  [0.7]\n",
      "9 's round !!!\n",
      "test2 output:  [0.7]\n",
      "10 's round !!!\n",
      "test2 output:  [0.7]\n",
      "11 's round !!!\n",
      "test2 output:  [0.7]\n",
      "12 's round !!!\n",
      "test2 output:  [0.7]\n",
      "13 's round !!!\n",
      "test2 output:  [0.7]\n",
      "14 's round !!!\n",
      "test2 output:  [0.7]\n",
      "15 's round !!!\n",
      "test2 output:  [0.7]\n",
      "16 's round !!!\n",
      "test2 output:  [0.7]\n",
      "17 's round !!!\n",
      "test2 output:  [0.7]\n",
      "18 's round !!!\n",
      "test2 output:  [0.7]\n",
      "19 's round !!!\n",
      "test2 output:  [0.7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import import_ipynb\n",
    "from importnb import Notebook\n",
    "with Notebook(): \n",
    "    import NN_HW3_sm as Nn\n",
    "from tqdm import tqdm, trange, notebook\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH5Q0QyZ97qs"
   },
   "source": [
    "## Data Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rMaZp5-4k2Zj"
   },
   "outputs": [],
   "source": [
    "tag_name = [\"age\", \"workclass\", \"fnlwgt\", \"edu\", \"education-num\", \"marital\", \"occup\", \"relation\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"country\", \"result\"]\n",
    "data_size = [7, 4, 21, 5, 6, 3, 4, 3, 3, 1, 20, 13, 7, 6, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8daLbDTlLCJ"
   },
   "source": [
    "## Read Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nYNcdCW38-g4"
   },
   "outputs": [],
   "source": [
    "def read_data(filename, name_col, i_sep, result_dict):\n",
    "    data_file = pd.read_csv(filename, header=None, names=name_col, sep=i_sep)\n",
    "    preprocess_data = np.empty(shape=(data_file.shape[0], data_file.shape[1]), dtype=np.float)\n",
    "    for i in range(data_file.shape[0]):\n",
    "    # for i in range(4):\n",
    "        row = data_file.iloc[i]\n",
    "#         preprocess_data[i][0] = np.binary_repr(row[\"age\"], 7)\n",
    "#         preprocess_data[i][1] = np.binary_repr( workclass_dict[row[\"workclass\"]], workclass_dict[\"bits\"] )\n",
    "#         preprocess_data[i][2] = np.binary_repr(row[\"fnlwgt\"], 21)\n",
    "#         preprocess_data[i][3] = np.binary_repr( edu_dict[row[\"edu\"]], edu_dict[\"bits\"] )\n",
    "#         preprocess_data[i][4] = np.binary_repr(row[\"education-num\"], 6)\n",
    "#         preprocess_data[i][5] = np.binary_repr( marital_dict[row[\"marital\"]], marital_dict[\"bits\"] )\n",
    "#         preprocess_data[i][6] = np.binary_repr( occup_dict[row[\"occup\"]], occup_dict[\"bits\"] )\n",
    "#         preprocess_data[i][7] = np.binary_repr( relation_dict[row[\"relation\"]], relation_dict[\"bits\"] )\n",
    "#         preprocess_data[i][8] = np.binary_repr( race_dict[row[\"race\"]], race_dict[\"bits\"] )\n",
    "#         preprocess_data[i][9] = sex_dict[row[\"sex\"]]\n",
    "#         preprocess_data[i][10] = np.binary_repr(row[\"capital-gain\"], 20)\n",
    "#         preprocess_data[i][11] = np.binary_repr(row[\"capital-loss\"], 13)\n",
    "#         preprocess_data[i][12] = np.binary_repr(row[\"hours-per-week\"], 7)\n",
    "#         preprocess_data[i][13] = np.binary_repr( country_dict[row[\"country\"]], country_dict[\"bits\"] )\n",
    "#         preprocess_data[i][14] = result_dict[row[\"result\"]]\n",
    "        \n",
    "        preprocess_data[i][0] = row[\"age\"]\n",
    "        preprocess_data[i][1] = workclass_dict[row[\"workclass\"]]\n",
    "        preprocess_data[i][2] = row[\"fnlwgt\"]\n",
    "        preprocess_data[i][3] = edu_dict[row[\"edu\"]]\n",
    "        preprocess_data[i][4] = row[\"education-num\"]\n",
    "        preprocess_data[i][5] = marital_dict[row[\"marital\"]]\n",
    "        preprocess_data[i][6] = occup_dict[row[\"occup\"]]\n",
    "        preprocess_data[i][7] = relation_dict[row[\"relation\"]]\n",
    "        preprocess_data[i][8] = race_dict[row[\"race\"]]\n",
    "        preprocess_data[i][9] = sex_dict[row[\"sex\"]]\n",
    "        preprocess_data[i][10] = row[\"capital-gain\"]\n",
    "        preprocess_data[i][11] = row[\"capital-loss\"]\n",
    "        preprocess_data[i][12] = row[\"hours-per-week\"]\n",
    "        preprocess_data[i][13] = country_dict[row[\"country\"]]\n",
    "        preprocess_data[i][14] = result_dict[row[\"result\"]]\n",
    "\n",
    "    for i in range(len(preprocess_data[0])):\n",
    "        max_v = np.max(preprocess_data[:,i])\n",
    "        min_v = np.min(preprocess_data[:,i])\n",
    "        preprocess_data[:,i] = (preprocess_data[:,i]-min_v)/(max_v - min_v)\n",
    "\n",
    "    return preprocess_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oIA-pUo97IU",
    "outputId": "cc0534b4-3421-4733-c7cb-09c59a52f263"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\nn_class\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_data = read_data('./adult/adult.data', tag_name, \", \", train_result_dict)\n",
    "test_data = read_data('./adult/adult.test', tag_name, \", \", test_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8zLQ9VJGi4n",
    "outputId": "c3d37a11-c123-498b-fc63-9a36e94c7a90"
   },
   "outputs": [],
   "source": [
    "# print(train_data.shape)\n",
    "# a = train_data[0][0]\n",
    "# print(a)\n",
    "# # a = train_data[0][1].astype(int)\n",
    "# # a = np.fromstring(a, dtype=int)\n",
    "# a = np.array(list(a), dtype=np.int)\n",
    "# print(len(a))\n",
    "# for i in range(len(a)):\n",
    "#   print(type(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-QysukoaafK5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30136986 0.625      0.0443019  0.         0.8        0.33333333\n",
      " 0.57142857 0.6        0.         1.         0.02174022 0.\n",
      " 0.39795918 0.         0.        ]\n",
      "[0.45205479 0.125      0.0482376  0.         0.8        0.\n",
      " 0.28571429 0.4        0.         1.         0.         0.\n",
      " 0.12244898 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input(x):\n",
    "#     ans = []\n",
    "#     for i in x:\n",
    "#         i = np.array(list(i), dtype=np.int)\n",
    "#         ans = np.append(ans, list(i))\n",
    "#     ans_1d = []\n",
    "    \n",
    "#     for i in ans:\n",
    "#         ans_1d = np.append(ans_1d, i, 0)\n",
    "#     return ans.copy()\n",
    "    return x\n",
    "\n",
    "ans = preprocess_input(train_data[0])\n",
    "ans1 = preprocess_input(train_data[1])\n",
    "print(ans)\n",
    "print(ans1)\n",
    "# print(train_data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(model, input_arr, layer_num):\n",
    "    for i, num in enumerate(layer_num):\n",
    "        if i == 0:\n",
    "            model.layer_list.append( Nn.Layer_vec(Nn.Sigmoid, Nn.d_Sigmoid, num, input_arr, True) )\n",
    "#         elif i == len(layer_num)-2:\n",
    "#             model.layer_list.append( Nn.Layer_vec(Nn.Sigmoid, Nn.d_Sigmoid, num, model.layer_list[i-1], False) )\n",
    "        else:\n",
    "            model.layer_list.append( Nn.Layer_vec(Nn.Sigmoid, Nn.d_Sigmoid, num, model.layer_list[i-1], False) )\n",
    "    model.layer_list.append( Nn.Softmax_Output(model.layer_list[len(model.layer_list)-1]) )\n",
    "    print(model.layer_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<NN_HW3_sm.Layer_vec object at 0x000001F009050940>, <NN_HW3_sm.Layer_vec object at 0x000001F009072128>, <NN_HW3_sm.Layer_vec object at 0x000001F009072CF8>, <NN_HW3_sm.Layer_vec object at 0x000001F0090726D8>, <NN_HW3_sm.Softmax_Output object at 0x000001F009050CC0>]\n",
      "1 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d263efcc25402298a06715159c271a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519d6692ae9c4318b5973089d6f487e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6863364718520658 , acc =  75.91904425539757 %\n",
      "Test loss:  0.7027179510373345 , acc =  76.3773723972729 %\n",
      "\n",
      "2 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3414e633bc61429cad462d804248af78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e274f8776694aaa8bba5dd48855cea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6893228165431365 , acc =  75.91904425539757 %\n",
      "Test loss:  0.6989500072420184 , acc =  76.3773723972729 %\n",
      "\n",
      "3 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cea150a4b654b98865d2c7654b55921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc6649582084a499dc39ab2a12e3541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6906989547974387 , acc =  75.91904425539757 %\n",
      "Test loss:  0.6970384337500943 , acc =  76.3773723972729 %\n",
      "\n",
      "4 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d74049e7cc4b76932cb984d0fbda54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0af2027c24e4fa1910efa8409aaf4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6914463919341328 , acc =  75.91904425539757 %\n",
      "Test loss:  0.6959361727059613 , acc =  76.3773723972729 %\n",
      "\n",
      "5 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c43c0aca2324a7d8e0c5aad0a259b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7121a8630945cbb13c2ab87d68ea63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6918974366414652 , acc =  75.91904425539757 %\n",
      "Test loss:  0.6952431515090064 , acc =  76.3773723972729 %\n",
      "\n",
      "6 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb9a9f74b4a4c77b601aa9fa68c7809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e607a707caa84dd2ba3ede997bba3f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.692190425314158 , acc =  75.91904425539757 %\n",
      "Test loss:  0.6947792763633482 , acc =  76.3773723972729 %\n",
      "\n",
      "7 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a404b922105640d7b4902ced444cc856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131ac34b19ac478ab9584cd9c728dad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.6923914237486931 , acc =  75.91904425539757 %\n",
      "Test loss:  0.6944536659534316 , acc =  76.3773723972729 %\n",
      "\n",
      "8 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df03eea8f2724638b541df8496e1720d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=32561.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f8ba3602b9416f99adf71fb67b12cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=16281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-b6c2241f1544>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0min_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0min_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mp_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mtrain_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0moutput_node_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_node_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Git\\Handcraft_NN\\code\\NN_HW3_sm.ipynb\u001b[0m in \u001b[0;36madjust_model\u001b[1;34m(self, ground_truth)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m# print(\"in \", i, \"-th layer\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Git\\Handcraft_NN\\code\\NN_HW3_sm.ipynb\u001b[0m in \u001b[0;36madjust_weight\u001b[1;34m(self, lr_rate)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;31m#         print(\"self.bp_vec: \", self.bp_vec, \"self.d_act_func(self.weighted_input: \", self.d_act_func(self.weighted_input), \"delta: \", delta)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_first\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m             \u001b[0mpass_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpass_bp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpass_v\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;31m#         print(\"data_w: \", delta_w)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#                         MODEL block                        #\n",
    "##############################################################\n",
    "\n",
    "with Notebook(): \n",
    "    import NN_HW3_sm as Nn\n",
    "# lr_rate = 0.00009\n",
    "epochs = 500\n",
    "\n",
    "lr_rate = 0.0001\n",
    "layer_nums = [100, 40, 5, 2]\n",
    "# layer_nums = [train_data.shape[1]-1, 7, 1]\n",
    "layer_input = preprocess_input(train_data[0])\n",
    "layer_input = layer_input[:len(layer_input)-1]\n",
    "test_m = Nn.Model(layer_nums, construct_model, layer_input, lr_rate)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "output_node_w = [[]]\n",
    "output_node_w = np.array([test_m.get_output_w()])\n",
    "# print(i, \"'s data !!!\")\n",
    "# p_data = preprocess_input(train_data[0])\n",
    "# test_m.cal_network(p_data[:14])\n",
    "# ans = test_m.get_result()\n",
    "# test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "# error.append(test_m.get_loss())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_err_cnt = 0\n",
    "    train_error = []\n",
    "    print(epoch+1, \"/\", epochs, \"epochs\")\n",
    "    train_progress = notebook.tqdm(total=len(train_data), desc=\"Training\")\n",
    "    test_progress = notebook.tqdm(total=len(test_data), desc=\"Testing\")\n",
    "    for i, input_data in enumerate(train_data):\n",
    "        # print(i, \"'s data !!!\")\n",
    "        train_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans_conf = test_m.get_result()\n",
    "        ans = np.argmax(ans_conf)\n",
    "        if abs(ans - p_data[len(p_data)-1]) > 0.5:\n",
    "            train_err_cnt += 1\n",
    "        # Adjust model weights\n",
    "#         if isinstance(p_data[len(p_data)-1], list):  \n",
    "#             test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "#         else:\n",
    "        \n",
    "#         self.bp_vec = np.full(self.neuron_num, p_data[len(p_data)-1)                   # Recieve value passed from postorier layer\n",
    "        in_result = np.full(2, 0);\n",
    "        in_result[int(p_data[len(p_data)-1])] = 1\n",
    "        p_loss = test_m.adjust_model(in_result)\n",
    "        train_error.append(p_loss)\n",
    "    output_node_w = np.append(output_node_w, [test_m.get_output_w()], 0)\n",
    "        \n",
    "    train_loss.append(np.average(train_error))\n",
    "    train_acc.append(1 - train_err_cnt/len(train_data) )\n",
    "    print(\"Train loss: \", np.average(train_error), \", acc = \", (1-train_err_cnt/len(train_data)) * 100, \"%\")\n",
    "    test_err_cnt = 0\n",
    "    test_error = []\n",
    "    for i, input_data in enumerate(test_data):\n",
    "        # print(i, \"'s data !!!\")\n",
    "        test_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans_conf = test_m.get_result()\n",
    "        ans = np.argmax(ans_conf)\n",
    "        if abs(ans - p_data[len(p_data)-1]) > 0.5:\n",
    "            test_err_cnt += 1\n",
    "            in_result = np.full(2, 0);\n",
    "        in_result[int(p_data[len(p_data)-1])] = 1\n",
    "        test_error.append(p_loss)\n",
    "        \n",
    "        \n",
    "    test_loss.append(np.average(test_error))\n",
    "    test_acc.append(1 - test_err_cnt/len(test_data) )\n",
    "    print(\"Test loss: \", np.average(test_error), \", acc = \", (1-test_err_cnt/len(test_data)) * 100, \"%\")\n",
    "    print()\n",
    "test_m.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loss: \", (train_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# print(output_node_w)\n",
    "x= np.arange(0,len(output_node_w))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, output_node_w[:,:,0])\n",
    "plt.title('Weight Change')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"value\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "x= np.arange(0,len(train_acc))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, train_acc, color='Blue', label='Train')\n",
    "plt.plot(x, test_acc, color='Orange', label='Validation')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) \n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(x, train_loss, color='Blue', label='Train')\n",
    "plt.plot(x, test_loss, color='Orange', label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Loss\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n0TeSbnPzQv"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                         MODEL block                        #\n",
    "##############################################################\n",
    "\n",
    "with Notebook(): \n",
    "    import NN_HW3 as Nn\n",
    "lr_rate = 0.1\n",
    "epochs = 500\n",
    "layer_nums = [train_data.shape[1]-1, 7, 1]\n",
    "layer_input = preprocess_input(train_data[0])\n",
    "layer_input = layer_input[:len(layer_input)-1]\n",
    "test_m = Nn.Model(Nn.Sigmoid, Nn.d_Sigmoid, layer_nums, layer_input, lr_rate)  # Correct when creating\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "output_node_w = [[]]\n",
    "output_node_w = np.array([test_m.get_output_w()])\n",
    "# print(i, \"'s data !!!\")\n",
    "# p_data = preprocess_input(train_data[0])\n",
    "# test_m.cal_network(p_data[:14])\n",
    "# ans = test_m.get_result()\n",
    "# test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "# error.append(test_m.get_loss())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_err_cnt = 0\n",
    "    train_error = []\n",
    "    print(epoch+1, \"/\", epochs, \"epochs\")\n",
    "    train_progress = notebook.tqdm(total=len(train_data), desc=\"Training\")\n",
    "    test_progress = notebook.tqdm(total=len(test_data), desc=\"Testing\")\n",
    "    for i, input_data in enumerate(train_data):\n",
    "        # print(i, \"'s data !!!\")\n",
    "        train_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans = test_m.get_result()\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            if abs(ans - p_data[len(p_data)-1][0]) > 0.5:\n",
    "                train_err_cnt += 1\n",
    "        else:\n",
    "            if abs(ans - p_data[len(p_data)-1]) > 0.5:\n",
    "                train_err_cnt += 1\n",
    "        train_error.append(test_m.get_loss())\n",
    "        # Adjust model weights\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            test_m.adjust_model(p_data[len(p_data)-1][0])\n",
    "        else:\n",
    "            test_m.adjust_model(p_data[len(p_data)-1])\n",
    "    output_node_w = np.append(output_node_w, [test_m.get_output_w()], 0)\n",
    "        \n",
    "    train_loss.append(np.average(train_error))\n",
    "    train_acc.append(1 - train_err_cnt/len(train_data) )\n",
    "    print(\"Train loss: \", np.average(train_error), \", acc = \", (1-train_err_cnt/len(train_data)) * 100, \"%\")\n",
    "    test_err_cnt = 0\n",
    "    test_error = []\n",
    "    for i, input_data in enumerate(test_data):\n",
    "        test_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data[:len(p_data)-1])\n",
    "        ans = test_m.get_result()\n",
    "        error = 0\n",
    "        if isinstance(p_data[len(p_data)-1], list):  \n",
    "            error = ans - p_data[len(p_data)-1][0]\n",
    "            if abs(error) > 0.5:\n",
    "                test_err_cnt += 1\n",
    "        else:\n",
    "            error = ans - p_data[len(p_data)-1]\n",
    "            if abs(error) > 0.5:\n",
    "                test_err_cnt += 1\n",
    "        test_error.append(np.dot(error, error) / 2)\n",
    "        \n",
    "    test_loss.append(np.average(test_error))\n",
    "    test_acc.append(1 - test_err_cnt/len(test_data) )\n",
    "    print(\"Test loss: \", np.average(test_error), \", acc = \", (1-test_err_cnt/len(test_data)) * 100, \"%\")\n",
    "    print()\n",
    "test_m.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "x= np.arange(0,len(output_node_w))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, output_node_w)\n",
    "plt.title('Weight Change')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"value\") \n",
    "\n",
    "# print(output_node_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaBqKsYpgaoZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "x= np.arange(0,len(train_acc))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, train_acc, color='Blue', label='Train')\n",
    "plt.plot(x, test_acc, color='Orange', label='Validation')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) \n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(x, train_loss, color='Blue', label='Train')\n",
    "plt.plot(x, test_loss, color='Orange', label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Loss\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RcxY2V6ijph"
   },
   "outputs": [],
   "source": [
    "error_cnt = 0\n",
    "for i, input_data in enumerate(test_data):\n",
    "  # print(i, \"'s data !!!\")\n",
    "  # print(input_data)\n",
    "  p_data = preprocess_input(input_data)\n",
    "  # print(p_data)\n",
    "  test_m.cal_network(p_data[:14])\n",
    "  ans = test_m.get_result()\n",
    "  # print(i ,test_m.get_loss())\n",
    "  # print(ans, p_data[len(p_data)-1][0])\n",
    "  if abs(ans - p_data[len(p_data)-1][0]) > 0.5:\n",
    "    error_cnt += 1\n",
    "  # test_m.adjust_model(p_data[len(p_data)-1])\n",
    "  # error.append(test_m.get_loss())\n",
    "# test_m.get_loss()\n",
    "# print(i, \"'s data !!!\")\n",
    "input_data = test_data[0]\n",
    "# print(input_data)\n",
    "p_data = preprocess_input(input_data)[:14]\n",
    "# print(p_data)\n",
    "test_m.cal_network(p_data)\n",
    "ans = test_m.get_result()\n",
    "# print(i ,test_m.get_loss())\n",
    "if abs(ans - p_data[len(p_data)-1][0]) > 0.5:\n",
    "  error_cnt += 1\n",
    "print(error_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C58cmj8kj7xy"
   },
   "outputs": [],
   "source": [
    "print(len(test_data))\n",
    "print(p_data[len(p_data)-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6N3g0aYAzUd"
   },
   "outputs": [],
   "source": [
    "a = [[1, 3], [2, 4]]\n",
    "b = [1, 3]\n",
    "for i in a:\n",
    "  print(len(i))\n",
    "w = 2*np.random.random((10))\n",
    "print(w)\n",
    "# for i in b:\n",
    "#   print(len(i))\n",
    "# print(len(a.shape))\n",
    "# print(len(b.shape))\n",
    "print(np.tile(b, (3,)))\n",
    "# preprocess_data = np.zeros((0,7))\n",
    "# print(preprocess_data)\n",
    "# preprocess_data = np.append(preprocess_data, [[0,1,2,3,4,5,6]], 0)\n",
    "# preprocess_data = np.append(preprocess_data, [[1,1,2,3,4,5,6]], 0)\n",
    "# print(preprocess_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0eI-4B9Dubcl"
   ],
   "name": "HW3_Q1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
