{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1604123731048,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "9ubVx3EUDU9W"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ97WqKes3b-"
   },
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1604123731341,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "fAr38nImf4XO"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Model class for the network model\n",
    "Store the model, including layer(construct by node), activation function\n",
    "'''\n",
    "class Model():\n",
    "    def __init__(self, layer_nums, create_func, input_arr, lr_rate):\n",
    "        self.layer_nums = layer_nums            # List of the number of each layer\n",
    "                                                # 0 => input number\n",
    "                                                # middle => layer number\n",
    "                                                # last => output number\n",
    "                    \n",
    "        self.layer_list = []                    # Store layer list\n",
    "        create_func(self, input_arr, layer_nums)            # Creating the network\n",
    "        \n",
    "        self.result = 0                         # Initial network result\n",
    "        self.lr_rate = lr_rate                  # Learning rate\n",
    "        self.loss = 0\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    '''\n",
    "    Calculate the network by using input data\n",
    "    '''\n",
    "    def cal_network(self, input):\n",
    "        self.layer_list[0].set_input(input.copy())\n",
    "        for i, layer in enumerate(self.layer_list):\n",
    "            layer.forwrad_pass()\n",
    "\n",
    "        return self.get_result()\n",
    "\n",
    "    '''\n",
    "    Set output errors, for the last layer only\n",
    "    '''\n",
    "    def set_output_error(self, error):\n",
    "        self.layer_list[len(self.layer_nums)-1].set_output_error(error)\n",
    "  \n",
    "    '''\n",
    "    Adjust nodes in network using backpropagation and ground truth\n",
    "    '''\n",
    "    def adjust_model(self, ground_truth):\n",
    "        error = self.result - ground_truth\n",
    "        self.loss = np.dot(error, error) / 2\n",
    "        if ground_truth == 1:\n",
    "            error = error * 3\n",
    "        self.set_output_error(error)\n",
    "        for i in range(len(self.layer_list)-1, -1, -1):\n",
    "            self.layer_list[i].adjust_weight(self.lr_rate)\n",
    "\n",
    "    '''\n",
    "    Return network result\n",
    "    '''\n",
    "    def get_result(self):\n",
    "        self.result = self.layer_list[len(self.layer_nums)-1].get_output()\n",
    "        return self.result\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.loss\n",
    "\n",
    "    def get_output_w(self):\n",
    "        w = self.layer_list[len(self.layer_list)-1].get_output_w()\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fezmbg647700"
   },
   "source": [
    "### Define Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1604123731343,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "NwoN8EKNvsnE"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Layer class for the network model\n",
    "Help model to handle neurons\n",
    "'''\n",
    "class Layer_vec():\n",
    "    '''\n",
    "    Initial layer\n",
    "    @param func - activation function\n",
    "    @param d_func - diviation of activation function\n",
    "    @param node_num - number of nodes in this layer\n",
    "    @param last_layer - last layer's node list\n",
    "    @param is_first - whether this layer is the first layer\n",
    "    '''\n",
    "    def __init__(self, func, d_func, node_num, last_layer, is_first):\n",
    "        # Activation Functions\n",
    "        self.act_func = func                                      # Activation function\n",
    "        self.d_act_func = d_func                                  # Diviation of activate function\n",
    "\n",
    "        # Input definition\n",
    "        if not is_first:\n",
    "            self.i_num = last_layer.get_node_num()               # Number of input node\n",
    "        else:\n",
    "            self.i_num = len(last_layer)                         # Number of input node\n",
    "        self.input_vec = np.full(self.i_num+1, 0.0)              # Initial input passed from\n",
    "        self.input_vec[self.i_num] = 1\n",
    "        self.neuron_num = node_num\n",
    "        self.last_layer = last_layer\n",
    "\n",
    "        # Calculation variables\n",
    "        self.w = np.random.randn(self.i_num+1, node_num) / np.sqrt(self.i_num+1)      # Initial weight\n",
    "\n",
    "        self.bp_vec = np.full(self.neuron_num, 0.0)                   # Recieve value passed from postorier layer\n",
    "        self.is_first = is_first                                  # Set to true if this node is at first layer\n",
    "        self.weighted_input = np.full(self.i_num, 0.0)           # Initial weighted input, use to store the value after the weighted input are sum up\n",
    "        self.result = np.full(self.neuron_num, 0.0)                   # Initial output result, equal to the value after subsituted weighted input into activation function\n",
    "        self.lr_rate = 0.005                                      # Learning rate of the node\n",
    "  \n",
    "    '''\n",
    "    Adjust weights, using backpropagation\n",
    "    For error function, e = y_predict - y_desire\n",
    "    For weight correction, w_n+1 = w_n - delta_w\n",
    "    '''\n",
    "    def adjust_weight(self, lr_rate):\n",
    "        self.lr_rate = lr_rate\n",
    "        # Calculate each weight for the specific previous node\n",
    "        delta = self.bp_vec * self.d_act_func(self.weighted_input)    # Dimation of layer node\n",
    "        delta_w = np.outer(self.input_vec, delta)\n",
    "        if (not self.is_first):\n",
    "            pass_v = np.dot(delta, self.w[0:len(self.w)-1, :].transpose())\n",
    "            self.last_layer.pass_bp(pass_v[0:len(self.input_vec)-1])\n",
    "        self.w = self.w - self.lr_rate * delta_w\n",
    "\n",
    "    def forwrad_pass(self):\n",
    "        if not self.is_first:\n",
    "            self.extract_value()\n",
    "        self.bp_vec = np.full(self.neuron_num, 0.0)      # Set bp value to zero, for later adjustment\n",
    "\n",
    "        self.weighted_input = np.dot(self.input_vec, self.w)\n",
    "        self.result = self.act_func(self.weighted_input)\n",
    "        return self.result\n",
    "    \n",
    "    '''\n",
    "    Pass backpropagation value back to previous layer\n",
    "    '''\n",
    "    def pass_bp(self, bp_value):\n",
    "        self.bp_vec = bp_value.copy()\n",
    "        \n",
    "    '''\n",
    "    Set input variable, used for first layer which recieve input value\n",
    "    @param x - input value for the network\n",
    "    '''\n",
    "    def set_input(self, x):\n",
    "        self.input_vec = x.copy()\n",
    "        if self.is_first:\n",
    "            self.input_vec = np.append(self.input_vec, 1)\n",
    "            \n",
    "    def extract_value(self):\n",
    "        self.input_vec = self.last_layer.get_output()\n",
    "        self.input_vec = np.append(self.input_vec, 1)\n",
    "\n",
    "    def get_node_num(self):\n",
    "        return self.neuron_num\n",
    "\n",
    "    def set_output_error(self, error):\n",
    "        if self.neuron_num != len(error):\n",
    "            print(\"Output layer and error doesn't match\")\n",
    "            return\n",
    "        self.pass_bp(error)\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.result\n",
    "    def get_output_w(self):\n",
    "        return self.w.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSApFupW7ojO"
   },
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1604123731345,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "e87aLLFDb-ia"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Activation function for the network\n",
    "'''\n",
    "def test_act_func(x):\n",
    "    return x*11\n",
    "\n",
    "'''\n",
    "ReLU\n",
    "'''\n",
    "def ReLU(x):\n",
    "    x[x<=0] = 0\n",
    "    return x.copy()\n",
    "\n",
    "'''\n",
    "Sigmoid\n",
    "'''\n",
    "def Sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znz66Njx7ueF"
   },
   "source": [
    "### Diviation of Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "code",
    "executionInfo": {
     "elapsed": 1140,
     "status": "ok",
     "timestamp": 1604123731346,
     "user": {
      "displayName": "E24056629王昶文",
      "photoUrl": "",
      "userId": "04499738007700106957"
     },
     "user_tz": -480
    },
    "id": "YgMss65OdtJS"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "'''\n",
    "Diviation of the activation function for the network\n",
    "'''\n",
    "def d_test_act_func(x):\n",
    "    return x+2\n",
    "\n",
    "'''\n",
    "Diviation of ReLU\n",
    "'''\n",
    "def d_ReLU(x):\n",
    "    x[x > 0] = 1\n",
    "    x[x <= 0] = 0\n",
    "    return x.copy()\n",
    "\n",
    "'''\n",
    "Diviation of Sigmoid\n",
    "'''\n",
    "def d_Sigmoid(x):\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    ans = s * (1 - s)\n",
    "    return ans"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZ5Ez+SCmycxN0mfXR93qW",
   "collapsed_sections": [
    "RSApFupW7ojO",
    "znz66Njx7ueF",
    "7_2vFmXhZB-a",
    "Fg7Rry3AZTia"
   ],
   "name": "NN_HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
